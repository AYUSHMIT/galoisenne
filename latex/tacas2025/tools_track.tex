% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{graphicx}
\usepackage{menukeys}
\usepackage{xcolor, soul}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
%\urlstyle{rm}
%
%\input{preamble.tex}

\colorlet{lred}{red!30}
\colorlet{lorange}{orange!30}
\colorlet{lgreen}{green!30}
\DeclareRobustCommand{\hlred}[1]{{\sethlcolor{lred}\hl{#1}}}
\DeclareRobustCommand{\hlorange}[1]{{\sethlcolor{lorange}\hl{#1}}}
\DeclareRobustCommand{\hlgreen}[1]{{\sethlcolor{lgreen}\hl{#1}}}

\usepackage{bussproofs}
\usepackage{ulem}


\makeatletter
\def\squigglyred{\bgroup \markoverwith{\textcolor{red}{\lower3\p@\hbox{\sixly \char58}}}\ULon}
\makeatother

\makeatletter
\def\squigglyblu{\bgroup \markoverwith{\textcolor{blue}{\lower3\p@\hbox{\sixly \char58}}}\ULon}
\makeatother

\makeatletter
\def\squigglyora{\bgroup \markoverwith{\textcolor{orange}{\lower3\p@\hbox{\sixly \char58}}}\ULon}
\makeatother

\newcommand{\err}[1]{\smash{\squigglyred{#1}{}}}
\newcommand{\erb}[1]{\smash{\squigglyblu{#1}{}}}
\newcommand{\ero}[1]{\smash{\squigglyora{#1}{}}}
\newcommand{\stirlingii}{\genfrac{\{}{\}}{0pt}{}}
\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\usepackage{amssymb}% http://ctan.org/pkg/amssymb

\usepackage{hyperref}
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\usepackage{inconsolata}
\usepackage{tikz}
\usetikzlibrary{automata, positioning, arrows}

\usepackage{listings}
\usepackage[skins,breakable,listings]{tcolorbox}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Color boxes
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tcbset{
  enhanced jigsaw,
  breakable,
  listing only,
%  boxsep=-1pt,
%  top=-1pt,
  width=0.9\textwidth,
  left=0.4cm,
  bottom=0cm,
  right=0cm,
  left skip=1.8cm,
  boxrule=1pt,
  overlay first={
    \node[black!50] (S) at (frame.south) {\Large\ding{34}};
    \draw[dashed,black!50] (frame.south west) -- (S) -- (frame.south east);
  },
  overlay middle={
    \node[black!50] (S) at (frame.south) {\Large\ding{34}};
    \draw[dashed,black!50] (frame.south west) -- (S) -- (frame.south east);
    \node[black!50] (S) at (frame.north) {\Large\ding{34}};
    \draw[dashed,black!50] (frame.north west) -- (S) -- (frame.north east);
  },
  overlay last={
    \node[black!50] (S) at (frame.north) {\Large\ding{34}};
    \draw[dashed,black!50] (frame.north west) -- (S) -- (frame.north east);
  },
  before={\par\vspace{5pt}},
  after={\par\vspace{\parskip}\noindent}
}

\definecolor{slightgray}{rgb}{0.90, 0.90, 0.90}

\usepackage{soul}
\makeatletter
\def\SOUL@hlpreamble{%
  \setul{}{3.0ex}%
  \let\SOUL@stcolor\SOUL@hlcolor%
  \SOUL@stpreamble%
}
\makeatother

\newcommand{\inline}[1]{%
  \begingroup%
  \sethlcolor{slightgray}%
  \hl{\ttfamily\footnotesize #1}%
  \endgroup
}

\newcommand{\tinline}[1]{%
  \begingroup%
  \sethlcolor{slightgray}%
  \hl{\ttfamily\tiny #1}%
  \endgroup
}

\newtcblisting{wholetidyinput}[1][]{%
  left=0.4cm,
  top=0.1cm,
%  width=0.9\textwidth,
  middle=0mm,
  boxsep=0mm,
  listing options={
    language=tidy,
    basicstyle=\ttfamily\scriptsize,
%numberstyle=\footnotesize,
    showstringspaces=false,
    tabsize=2,
    breaklines=true,
    numbers=none,
    inputencoding=utf8,
    escapeinside={(*@}{@*)},
    #1
  },
  underlay unbroken and first={%
    \path[draw=none] (interior.north west) rectangle node[white]{\includegraphics[width=4mm]{../figures/tidyparse_logo.png}} ([xshift=-10mm,yshift=-8mm]interior.north west);
  }
}

%\usepackage{sourcecodepro}
%\usepackage{newtxtt}
%\usepackage{zi4}
%\usepackage{FiraMono}
%\usepackage{DejaVuSansMono}

%\usepackage{fontspec}
%\setmonofont[Scale=0.8]{JetBrainsMono}[
%  Contextuals={Alternate},
%  Path=./font/,
%  Extension = .ttf,
%  UprightFont=*-Regular,
%  BoldFont=*-Bold,
%  ItalicFont=*-Italic,
%  BoldItalicFont=*-BoldItalic
%]

\begin{document}
%
\title{Realtime syntax repair with resource constraints}
%
\titlerunning{Realtime syntax repair with resource constraints}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Breandan Considine\inst{1} \and
Jin Guo\inst{1}\and
Xujie Si\inst{2}}
%
\authorrunning{Considine et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{McGill University, Montr\'eal, QC H2R 2Z4, Canada\\
\email{\{breandan.considine@mail, jguo@cs\}.mcgill.ca}\and
University of Toronto, Toronto, ON, M5S 1A1 Canada\\
\email{six@utoronto.ca}}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
  We describe the implementation of a tool for real-time syntax correction in an IDE. Upon activation, our tool takes a syntactically invalid source code fragment around the caret position, and produces a small set of suggested repairs. We model the problem of syntax repair as a structured prediction task, whose goal is to generate the most likely valid repair in a small edit distance of the invalid code fragment.
  \keywords{Error correction \and CFL reachability \and Langauge games.}
\end{abstract}

\section{Introduction}

Syntax errors are a familiar nuisance for software developers. Whenever a syntax error is detected, the IDE typically flags the offending code fragment, but offers little guidance on how it should be fixed. The developer must inspect the code and manually apply the appropriate fix through a process of trial and error. This process can be distracting and time-consuming, especially for novice developers. In this paper, we describe a tool for automatic syntax repair in an IDE.

We propose a new approach to syntax repair and accompanying tool that suggests a small set of repairs to the user, which are guaranteed to be valid, minimal and natural. Our repair tool is a fusion of two widely available components: grammars and language models. At first glance, these two models are not obviously synergistic: the grammar is a deterministic, formal model of the language, while the language model is only an approximate generator of linguistic patterns. However, we show that by carefully integrating them, it is possible to generate repairs that are always correct and highly natural.

Language models are statistical models that generate natural sequences of text, however, these models make no guarantees about the validity of the generated text. Given a sequence of previous tokens, $\sigma_{0}, \ldots, \sigma_{n-1}$, an autoregressive language model outputs a distribution over the next most likely token, $\sigma_n$.

Almost every programming language ever developed is syntactically context-free, which means the syntax of the language can be expressed as a context-free grammar (CFG). This grammar can be used to recognize the validity of a given input sequence, or force an autoregressive language model to generate only syntactically valid sequences by blocking out invalid tokens during inference.

Likewise, this grammar can be also used to construct a synthetic grammar, recognizing all and only valid sequences within a certain edit distance of a broken source code fragment using language intersection techniques. Our approach uses a pretrained language model to sample repair candidates from this synthetic grammar. We rank the results by negative log likelihood under the language model, and present the top $k$ candidates to the user. The user can then select the most appropriate repair from the list, or continue to edit the code manually.

Let us consider an example. Suppose the user has written the following code fragment: \texttt{v = df.iloc(5:, 2:)}. Assuming an alphabet of just a hundred lexical tokens, this tiny statement has millions of possible two-token edits, yet only six of those possibilities are accepted by the Python parser:

\begin{figure}[h!]
  \noindent\begin{tabular}{@{}l@{\hspace{10pt}}l@{\hspace{10pt}}l@{}}
  (1) \texttt{v = df.iloc(5\hlred{:}, 2\hlorange{,})} & (3) \texttt{v = df.iloc(5\hlgreen{[}:, 2:\hlgreen{]})} & (5) \texttt{v = df.iloc\hlorange{[}5:, 2:\hlorange{]}} \\
  \rule{0pt}{4ex}(2) \texttt{v = df.iloc(5\hlorange{)}, 2\hlorange{(})} & (4) \texttt{v = df.iloc(5\hlred{:}, 2\hlred{:})} & (6) \texttt{v = df.iloc(5\hlgreen{[}:, 2\hlorange{]})}\\
  \end{tabular}\vspace{-5pt}
\end{figure}

\noindent To find these repairs, we first lexicalize the input as follows:

\begin{verbatim}
  v = df.iloc(5:, 2:)
  v    = df   . iloc ( 5      : , 2      : )
  NAME = NAME . NAME ( NUMBER : , NUMBER : )
\end{verbatim}

\noindent Next, we will construct an automaton that recognizes every string within a certain edit distance of the input. We will depict the process for a simpler example, where the grammar is $S \rightarrow \texttt{( )} \mid \texttt{( } S \texttt{ )} \mid S S$ and the broken code is \texttt{( ) )}.\vspace{-0.3cm}

\begin{figure}[h!]
  \includegraphics[width=\textwidth]{flow.pdf}\vspace{-1pt}
  \caption{Simplified dataflow. Given a grammar and broken code fragment, we create an automaton generating the language of small edits, then intersect it with the grammar to produce an intersection grammar, which can be simplified to a DFA and decoded.}\label{fig:arch_simp}
\end{figure}\vspace{-0.3cm}

To generate the repairs, we first construct an automaton that recognizes every string within a certain edit distance of the input. We then construct an intersection grammar, which recognizes all and only valid sequences within a certain edit distance of the input. This grammar is known to be non-recursive, and can be simplified to a deterministic finite automaton (DFA) using standard techniques. Finally, we decode the DFA to produce a list of repair candidates, which we rank by negative log likelihood under the language model.

Now that we have a high-level overview of our approach, we will demonstrate a few of the capabilities of our tool by means of some usage examples.

\section{Usage examples}

Tidyparse offers a convenient user interface featuring a text editor, a grammar editor and a parse tree viewer for interactive prototyping. All tokens are delimited by whitespace. For example, suppose we have the following grammar:

\begin{wholetidyinput}
  S -> S and S | S xor S | ( S ) | true | false | ! S(*@\caret{ }@*)
\end{wholetidyinput}

\noindent Syntax repair is the primary intended use case of our tool. If given an unparsable string, it will return an ordered set of suggestions how to fix it, highlighted with colors, where \hlgreen{green} is insertion, \hlorange{orange} is substitution and \hlred{red} is deletion.

\begin{tcolorbox}[
top=0.1cm,
middle=0mm,
boxsep=0mm,
underlay unbroken and first={%
  \path[draw=none] (interior.north west) rectangle node[white]{\includegraphics[width=4mm]{../figures/tidyparse_logo.png}} ([xshift=-10mm,yshift=-9mm]interior.north west);
}]
\begin{lstlisting} [language=tidy, basicstyle=\ttfamily\scriptsize, escapeinside={(*@}{@*)}]
true and ( false or and true false(*@\caret{ }@*)
\end{lstlisting}
\tcblower
\begin{lstlisting} [language=tidy, basicstyle=\ttfamily\scriptsize, escapeinside={(*@}{@*)}]
1. true and ( false or (*@\hlorange{!}@*) true (*@\hlorange{)}@*)
2. true and ( false or (*@\hlgreen{<S>}@*) and true (*@\hlorange{)}@*)
3. true and ( false or (*@\hlorange{(}@*) true (*@\hlorange{)}@*) (*@\hlgreen{)}@*)
...
9. true and ( false or (*@\hlgreen{!}@*) (*@\hlgreen{<S>}@*) (*@\hlgreen{)}@*) and true (*@\hlred{false} @*)
\end{lstlisting}
\end{tcolorbox}
Code completion is the secondary intended use case. Given a string containing holes, our tool will return several possible completions:

\begin{tcolorbox}[
top=0.1cm,
middle=0mm,
boxsep=0mm,
underlay unbroken and first={%
  \path[draw=none] (interior.north west) rectangle node[white]{\includegraphics[width=4mm]{../figures/tidyparse_logo.png}} ([xshift=-10mm,yshift=-9mm]interior.north west);
}]
\begin{lstlisting} [language=tidy, basicstyle=\ttfamily\scriptsize, escapeinside={(*@}{@*)}]
true _ _ _ ( false _ ( _ _ _ _ ! _ _ ) _ _ _ _(*@\caret{ }@*)
\end{lstlisting}
\tcblower
\begin{lstlisting} [language=tidy, basicstyle=\ttfamily\scriptsize, escapeinside={(*@}{@*)}]
1. true (*@\hlorange{xor}@*) (*@\hlorange{!}@*) ( false (*@\hlorange{xor}@*) ( (*@\hlorange{<S>}@*) (*@\hlorange{)}@*) (*@\hlorange{or}@*) ! (*@\hlorange{<S>}@*) ) (*@\hlorange{xor}@*) (*@\hlorange{<S>}@*)
2. true (*@\hlorange{xor}@*) (*@\hlorange{!}@*) ( false (*@\hlorange{and}@*) ( (*@\hlorange{<S>}@*) (*@\hlorange{)}@*) (*@\hlorange{or}@*) ! (*@\hlorange{<S>}@*) ) (*@\hlorange{xor}@*) (*@\hlorange{<S>}@*)
3. true (*@\hlorange{xor}@*) (*@\hlorange{!}@*) ( false (*@\hlorange{and}@*) ( (*@\hlorange{<S>}@*) (*@\hlorange{)}@*) (*@\hlorange{and}@*) ! (*@\hlorange{<S>}@*) ) (*@\hlorange{xor}@*) (*@\hlorange{<S>}@*)
4. true (*@\hlorange{xor}@*) (*@\hlorange{!}@*) ( false (*@\hlorange{and}@*) ( (*@\hlorange{<S>}@*) (*@\hlorange{)}@*) (*@\hlorange{and}@*) ! (*@\hlorange{<S>}@*) ) (*@\hlorange{and}@*) (*@\hlorange{<S>}@*)
...
\end{lstlisting}
\end{tcolorbox}
%Since CFLs are closed under homomorphisms, it is possible to unify lexing and parsing, however most languages explicitly define a separate lexer, which we avail to substitute named identifiers with their type. Given an invalid string, the tool will first abstract the raw characters, generate edits in the abstract token space, then remap successful repairs back to character space as shown below:
%
%\hspace{-0.4cm}\begin{minipage}[t]{0.485\textwidth}
%                 \begin{tcolorbox}[
%                 left skip=0.7cm,
%                 left=0.35cm,
%                 right=0cm,
%                 top=0.1cm,
%                 middle=0mm,
%                 boxsep=0mm,
%                 underlay unbroken and first={%
%                   \path[draw=none] (interior.north west) rectangle node[white]{\includegraphics[width=4mm]{../figures/tidyparse_logo.png}} ([xshift=-10mm,yshift=-9mm]interior.north west);
%                 }]
%                 \begin{lstlisting} [hbox, language=tidy, basicstyle=\ttfamily\scriptsize, escapeinside={(*@}{@*)}]
%d = sum([foo(i] for i in vals))(*@\caret{ }@*)
%                 \end{lstlisting}
%                 \tcblower
%                 \begin{lstlisting} [hbox, language=tidy, basicstyle=\ttfamily\scriptsize, escapeinside={(*@}{@*)}]
%1. d = sum([foo(i(*@\hlorange{)}@*) for i in vals(*@\hlorange{]}@*))
%2. d = sum([(i(*@\hlorange{)}@*) for i in vals(*@\hlorange{]}@*))
%3. d = sum([foo(*@\hlorange{.}@*)i for i in vals(*@\hlorange{]}@*))
%4. d = sum([foo((*@\hlgreen{+}@*)i(*@\hlorange{)}@*) for i in vals(*@\hlorange{]}@*))
%                 \end{lstlisting}
%                 \end{tcolorbox}
%\end{minipage}
%\hspace{0.05cm}
%\begin{minipage}[t]{0.51\textwidth}
%  \begin{tcolorbox}[
%  left skip=0.7cm,
%  left=0.35cm,
%  right=0cm,
%  top=0.1cm,
%  middle=0mm,
%  boxsep=0mm,
%  underlay unbroken and first={%
%    \path[draw=none] (interior.north west) rectangle node[white]{\includegraphics[width=4mm]{../figures/tidyparse_logo.png}} ([xshift=-10mm,yshift=-9mm]interior.north west);
%  }]
%  \begin{lstlisting} [language=tidy, basicstyle=\ttfamily\scriptsize, escapeinside={(*@}{@*)}]
%w = w ( [ w ( w ] for w in w ) )
%  \end{lstlisting}
%  \tcblower
%  \begin{lstlisting} [language=tidy, basicstyle=\ttfamily\scriptsize, escapeinside={(*@}{@*)}]
%1. w = w ( [ w ( i (*@\hlorange{)}@*) for i in w (*@\hlorange{]}@*) )
%2. w = w ( [ (*@\hlred{w}@*) ( w (*@\hlorange{)}@*) for w in w (*@\hlorange{]}@*) )
%3. w = w ( [ w (*@\hlorange{.}@*) w (*@\hlred{)}@*)  for w in w (*@\hlorange{]}@*) )
%4. w = w ( [ w ( (*@\hlgreen{+}@*) w (*@\hlorange{)}@*) for w in w (*@\hlorange{)}@*) )
%  \end{lstlisting}
%  \end{tcolorbox}
%\end{minipage}
For simplicity, it is also possible to define a grammar and string side-by-side, as shown in the untyped $\lambda$-calculus example below:

\begin{tcolorbox}[
top=0.1cm,
middle=0mm,
boxsep=0mm,
underlay unbroken and first={%
  \path[draw=none] (interior.north west) rectangle node[white]{\includegraphics[width=4mm]{../figures/tidyparse_logo.png}} ([xshift=-10mm,yshift=-9mm]interior.north west);
}]
\begin{lstlisting} [language=tidy, basicstyle=\ttfamily\scriptsize, escapeinside={(*@}{@*)}]
sxp -> (*@$\lambda$@*) var . sxp | sxp sxp | var | ( sxp )
var -> a | b | c | f | x | y | z
---
( (*@$\lambda$@*) f . ( (*@$\lambda$@*) x . f ( x x ) ) ( (*@$\lambda$@*) x . f ( x x ) (*@\caret{ }@*)
\end{lstlisting}
\tcblower
\begin{lstlisting} [language=tidy, basicstyle=\ttfamily\scriptsize, escapeinside={(*@}{@*)}]
1. ( (*@$\lambda$@*) f . ( (*@$\lambda$@*) x . f ( x x ) ) (*@\hlorange{)}@*) (*@$\lambda$@*) x . f ( x x )
2. ( (*@$\lambda$@*) f . ( (*@$\lambda$@*) x . f ( x x ) ) (*@\hlorange{x}@*) (*@\hlgreen{)}@*) (*@$\lambda$@*) x . f ( x x )
3. ( (*@$\lambda$@*) f . ( (*@$\lambda$@*) x . f ( x x ) ) ( (*@$\lambda$@*) x . f ( x(*@\hlred{ }@*)) (*@\hlgreen{)}@*) (*@\hlgreen{)}@*)
\end{lstlisting}
\end{tcolorbox}
\noindent By default, Tidyparse samples the finite intersection language uniformly without replacement. Customizing the order of repair ranking is possible using a programmatic interface.


\subsection{Grammar assistance}

Tidyparse uses a CFG to parse the CFG, so it can provide editing assistance while the user is designing the CFG. For example, if the CFG does not parse, will suggest a list of possible fixes.% In the future, we intend to use this functionality to perform example-based codesign and grammar induction.

  \begin{tcolorbox}[
  left=0.35cm,
  right=0cm,
  top=0.1cm,
  middle=0mm,
  boxsep=0mm,
  underlay unbroken and first={%
    \path[draw=none] (interior.north west) rectangle node[white]{\includegraphics[width=4mm]{../figures/tidyparse_logo.png}} ([xshift=-10mm,yshift=-9mm]interior.north west);
  }]
  \begin{lstlisting} [language=tidy, basicstyle=\ttfamily\scriptsize, escapeinside={(*@}{@*)}]
B ::= true | false | (*@\caret{ }@*)
  \end{lstlisting}
  \tcblower
  \begin{lstlisting} [language=tidy, basicstyle=\ttfamily\scriptsize, escapeinside={(*@}{@*)}]
1. B (*@\hlorange{->}@*) true | false (*@\hlred{ }@*)
2. B (*@\hlorange{->}@*) true | false (*@\hlorange{<RHS>}@*)
3. B (*@\hlorange{->}@*) true | false | (*@\hlgreen{<RHS>}@*)
  \end{lstlisting}
  \end{tcolorbox}

\subsection{Interactive nonterminal expansion}

Users can interactively build up a complex expression by placing the caret over a nonterminal they wish to expand, then pressing \keys{\ctrl + \SPACE} to receive a list of possible substitutions.

\begin{tcolorbox}[
top=0.1cm,
middle=0mm,
boxsep=0mm,
underlay unbroken and first={%
  \path[draw=none] (interior.north west) rectangle node[white]{\includegraphics[width=4mm]{../figures/tidyparse_logo.png}} ([xshift=-10mm,yshift=-9mm]interior.north west);
}]
\begin{lstlisting} [language=tidy, basicstyle=\ttfamily\scriptsize, escapeinside={(*@}{@*)}]
true and ( false or <(*@\caret{S}@*)> and true )
\end{lstlisting}
\tcblower
\begin{lstlisting} [language=tidy, basicstyle=\ttfamily\scriptsize, escapeinside={(*@}{@*)}]
1. true and ( false or (*@\hlorange{true}@*) and true )
2. true and ( false or (*@\hlorange{false}@*) and true )
3. true and ( false or (*@\hlorange{! <S>}@*) and true )
\end{lstlisting}
\end{tcolorbox}

\subsection{Nonterminal stubs}

Tidyparse augments CFGs with two additional rules, which are desugared into a vanilla CFG before parsing. The first rule, $\alpha\textsc{-sub}$, allows the user to define a nonterminal parameterized by $\alpha$, a non-recursive nonterminal in the same the CFG representing some finite type and its inhabitants. $\alpha\textsc{-sub}$ replaces all productions containing $\langle\alpha\rangle$ with the terminals in their transitive closure, $\alpha \rightarrow^* \beta$. The second rule, $\alpha\textsc{-int}$, introduces homonymous terminals for each user-defined nonterminal.

\begin{figure}[h!]
  \begin{prooftree}
    \AxiomC{$\mathcal{G} \vdash (w\langle\alpha\rangle \rightarrow x z) \in P$}
    \AxiomC{$\alpha^* : \{\beta \mid (\alpha \rightarrow^* \beta) \in P\}$}
    \RightLabel{$\alpha\textsc{-sub}$}
    \BinaryInfC{$\mathcal{G} \vdash \forall \beta \in \alpha^*.(w\langle\alpha\rangle \rightarrow x z)[\beta/\alpha] \in P'$}
  \end{prooftree}
  \begin{prooftree}
    \AxiomC{$\mathcal{G} \vdash v \in V$}
    \RightLabel{$\langle\cdot\rangle\textsc{-int}$}
    \UnaryInfC{$\mathcal{G} \vdash (v \rightarrow \langle v\rangle) \in P$}
  \end{prooftree}
\end{figure}

Tidyparse can also perform a limited form of type checking. Typed expressions are automatically expanded into ordinary nonterminals using the $\alpha\textsc{-sub}$ rule, for example when parsing an expression of the form $x + y$, the grammar will recognize \texttt{true + false} and \texttt{1 + 2}, but not \texttt{1 + true}.

\begin{tcolorbox}[
top=0.1cm,
middle=0mm,
boxsep=0mm,
underlay unbroken and first={%
  \path[draw=none] (interior.north west) rectangle node[white]{\includegraphics[width=4mm]{../figures/tidyparse_logo.png}} ([xshift=-10mm,yshift=-9mm]interior.north west);
}]
\begin{lstlisting} [language=tidy, basicstyle=\ttfamily\scriptsize, escapeinside={(*@}{@*)}]
E<X> -> E<X> + E<X> | E<X> * E<X> | ( E<X> )
X -> Int | Bool

# The above grammar is equivalent to writing:

E<Int> -> E<Int> + E<Int> | E<Int> * E<Int>
E<Bool> -> E<Bool> + E<Bool> | E<Bool> * E<Bool>
\end{lstlisting}
\end{tcolorbox}

\subsection{Syntax highlighting}

Subsequences which are partly parseable are underlined in blue. Unparsable alphabetic tokens are marked orange. All other tokens are marked red.

\begin{tcolorbox}[
top=0.1cm,
middle=0mm,
boxsep=0mm,
underlay unbroken and first={%
  \path[draw=none] (interior.north west) rectangle node[white]{\includegraphics[width=4mm]{../figures/tidyparse_logo.png}} ([xshift=-10mm,yshift=-9mm]interior.north west);
}]
\begin{lstlisting} [language=tidy, basicstyle=\ttfamily\scriptsize, escapeinside={(*@}{@*)}]
(*@\erb{( true xor false ) and true}@*) (*@\ero{xor}@*) (*@\ero{and}@*) (*@\err{not}@*) (*@\ero{false}@*)
\end{lstlisting}
\end{tcolorbox}

\section{Related work}

Many methods to sample from language models have been proposed. Some of these guarantee that all samples are grammatically valid. Others guarantee that all grammatically valid samples are generable. The trick is not just synthesizing valid functions, but doing so in a parallel communication-free manner, without compromising soundness or completeness. The goal is to massively scale up a discrete sampler without replacement.

This problem is also closely related to model counting in the CSP literature, so a practical speedup could lead to improvements on a lot of interesting downstream benchmarks.

In general, the problem of program induction from input-output examples is not well-posed, so specialized solvers that can make stronger assumptions will usually have an advantage on domain-specific benchmarks. Most existing program synthesizers do not satisfy all of these desiderata, e.g., soundness (\textbf{S}), completeness (\textbf{S}), naturalness (\textbf{N}), and parallelism (||). It depends on how you define ||, but basically, we want to decode in parallel. So an LLM that uses a GPU we do not consider to be ``parallel'' in the sense we mean here.

\newcommand{\tidyparse}{\href{https://arxiv.org/pdf/2408.01849}{Tidyparse}~\cite{considine2023pragmatic}}
\newcommand{\seqtoparse}{\href{https://pg.ucsd.edu/publications/Seq2Parse-neurosymbolic-parse-error-repair_OOPSLA-2022.pdf}{Seq2Parse}~\cite{sakkas2022seq2parse}}
\newcommand{\bifi}{\href{https://arxiv.org/pdf/2106.06600}{BIFI}~\cite{yasunaga2021break}}
\newcommand{\ordinalfix}{\href{https://arxiv.org/pdf/2309.06771}{OrdinalFix}~\cite{zhang2023ordinalfix}}
% https://boxbase.org/entries/2019/nov/25/error-correcting-earley-algorithm/
\newcommand{\ahopeterson}{\href{https://epubs.siam.org/doi/10.1137/0201022}{Aho/Peterson}~\cite{aho1972minimum}}

\begin{table}[h]
  \begin{tabular}{c|cccccc}
    & \textbf{S}       & \textbf{C} & \textbf{N} & \textbf{Theory} & ||     & \textbf{Tool} \\\hline
    \tidyparse   & \cmark           & \cmark & \cmark & CFG$_\cap$      & \cmark & IDE-ready     \\
    \seqtoparse  & \cmark$^\dagger$ & \xmark & \cmark & CFG             & \xmark & Python        \\
    \bifi        & \xmark           & \xmark & \cmark & $\Sigma^*$      & \xmark & Python        \\
    \ordinalfix  & \cmark           & \xmark & \xmark & CFG+            & \xmark & Rust          \\
    \ahopeterson & \cmark           & \xmark & \xmark & CFG             & \xmark & None          \\
  \end{tabular}
\end{table}

Now, we consider just LLM-based SyGuS synthesizers.

\newcommand{\outlines}{\href{https://arxiv.org/pdf/2307.09702}{Outlines}~\cite{willard2023efficient}}
\newcommand{\syncode}{\href{https://arxiv.org/pdf/2403.01632}{SynCode}~\cite{ugare2024improving}}
\newcommand{\gad}{\href{https://arxiv.org/pdf/2405.21047}{GAD}~\cite{park2024grammar}}
\newcommand{\codeguard}{\href{https://arxiv.org/pdf/2405.00218}{CodeGuard+}~\cite{fu2024constrained}}
\newcommand{\flap}{\href{https://arxiv.org/pdf/2403.05766}{FLAP}~\cite{roy2024flap}}
\newcommand{\domino}{\href{https://arxiv.org/pdf/2403.06988}{DOMINO}~\cite{beurer2024guiding}}

\begin{table}[h]
  \begin{tabular}{c|cccccc}
    & \textbf{S}       & \textbf{C}       & \textbf{N} & \textbf{Theory} & ||     & \textbf{Tool} \\\hline
    \outlines  & \cmark$^\dagger$ & \cmark$^\dagger$ & \cmark     & CFG             & \xmark & Python        \\
    \syncode   & \cmark           & ?                & \cmark     & CFG             & \xmark & Python        \\
    \gad       & \cmark           & ?                & \cmark     & CFG             & \xmark & Python        \\
    \codeguard & \cmark           & ?                & \cmark     & CFG             & \xmark & Python        \\
    \flap      & \cmark           & ?                & \cmark     & CFG             & \xmark & Python        \\
    \domino    & \cmark           & \xmark           & \cmark     & CFG             & \xmark & Python
  \end{tabular}
\end{table}


Also, we consider discrete program search and enumerative search techniques that do not use an LLM, but allow some semantic constraints on the generated program.

\newcommand{\boltzmann}{\href{https://arxiv.org/pdf/2206.06668}{Boltzmann Brain}~\cite{bendkowski2022automatic}}
\newcommand{\dps}{\href{https://arxiv.org/pdf/2403.06988}{IntCalc}~\cite{beurer2024guiding}}

\begin{table}[h]
  \begin{tabular}{c|cccccc}
    & \textbf{S} & \textbf{C} & \textbf{N} & \textbf{Theory} & ||     & \textbf{Tool} \\\hline
    Boltzmann Brain~\cite{bendkowski2022automatic} & \cmark     & \cmark     & \cmark     & UT$\lambda$C    & \cmark & Python        \\
    OrdinalFix~\cite{zhang2023ordinalfix}          & \cmark     & ?          & \xmark     & N/A             & \cmark & Rust          \\
    Bend/DPS                                       & \cmark     & ?          & ?          & IntCalc         & \cmark & CUDA
  \end{tabular}
\end{table}

\section{Conclusion}


%bibliography
\bibliographystyle{splncs04}
\bibliography{../bib/acmart}

\end{document}