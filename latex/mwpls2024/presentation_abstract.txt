Title: Let's wrap this up! Incremental structured decoding with resource constraints

Language models are known to struggle with few-shot constraint satisfaction tasks, such as responding within a fixed number of tokens or without using certain words. These scenarios typically arise in programming-related tasks such as code completion and program repair. We propose a novel incremental approach to constrained sequence generation based on a theory of Brzozowski (1964). Our approach constructs a valid sequence from left-to-right using next-token probabilities from the language model to steer the decoder towards natural solutions. We demonstrate the effectiveness of this technique on the problem of syntax repair, where it enjoys a significant advantage over state-of-the-art neural repair models in terms of precision on blind recovery of human repairs, while ensuring that every valid sequence is generable and every generable sequence is valid.