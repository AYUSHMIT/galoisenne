%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[sigplan,10pt,review,anonymous]{acmart}
%\settopmatter{printfolios=false,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[sigplan,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[sigplan,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[sigplan,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
\documentclass[sigplan,nonacm]{acmart}\settopmatter{printfolios=false,printccs=false,printacmref=false}

%% Conference information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmConference[ARRAY'22]{ACM SIGPLAN Conference on Programming Languages}{June 13, 2022}{San Diego, CA, USA}
%\acmYear{2018}
%\acmISBN{} % \acmISBN{978-x-xxxx-xxxx-x/YY/MM}
%\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
%\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

\usepackage{dsfont}
\usepackage{stmaryrd}
\usepackage{colortbl}
\usepackage{hyperref}

%% Bibliography style
\bibliographystyle{acmart}

\input{preamble.tex}
\begin{document}

%% Title information
\title{Tidyparse: Real-Time Context Free Error Correction}
\begin{abstract}
Tidyparse is a program synthesizer that performs real-time error correction for context free languages.
Given both an arbitrary context free grammar (CFG) and an invalid string, the tool lazily generates admissible repairs while the author is typing, ranked by Levenshtein edit distance.
 Repairs are guaranteed to be complete, grammatically consistent and minimal.
 Tidyparse is the first system of its kind offering these guarantees in a real-time editor. To accelerate code completion, we design and implement a novel incremental parser-synthesizer that transforms CFGs onto a dynamical system over finite field arithmetic, enabling us to suggest syntax repairs in-between keystrokes. We have released an IDE plugin demonstrating the system described.\footnote{https://plugins.jetbrains.com/plugin/19570-tidyparse}
\end{abstract}

\author{Breandan Mark Considine}
\affiliation{
  \institution{McGill University}
}
\email{bre@ndan.co}

\author{Jin Guo}
\affiliation{
  \institution{McGill University}
}
\email{jguo@cs.mcgill.ca}

\author{Xujie Si}
\affiliation{
  \institution{McGill University}
}
\email{xsi@cs.mcgill.ca}

\maketitle

\section{Introduction}

Modern research on error correction can be traced back to the early days of coding theory, when researchers designed \textit{error-correcting codes} (ECCs) to denoise transmission errors induced by external interference, whether due to collision with a high-energy proton, manipulation by an adversary or some typographical mistake. In this context, \textit{code} can be any logical representation for communicating information between two parties (such as a human and a computer), and an ECC is a carefully-designed code which ensures that even if some portion of the message should be corrupted through accidental or intentional means, one can still recover the original message by solving a linear system of equations. In particular, we frame our work inside the context of errors arising from human factors in computer programming.

In programming, most such errors initially manifest as syntax errors, and though often cosmetic, manual repair can present a significant challenge for novice programmers. The ECC problem may be refined by introducing a language, $\mathcal{L} \subset \Sigma^*$ and considering admissible edits transforming an arbitrary string, $s \in \Sigma^*$ into a string, $s'\in\mathcal{L}$. Known as \textit{error-correcting parsing} (ECP), this problem was well-studied in the early parsing literature, cf. Aho and Peterson~\cite{aho1972minimum}, but fell out of favor for many years, perhaps due to its perceived complexity. By considering only minimal-length edits, ECP can be reduced to the so-called \textit{language edit distance} (LED) problem, recently shown to be subcubic~\cite{bringmann2019truly}, suggesting its possible tractability. Previous results on ECP and LED were primarily of a theoretical nature, but now, thanks to our contributions, we have finally realized a practical prototype.

\section{Prior work}

Prior work in this area follows two main streams. Kats~\cite{kats2009providing} and deJong~\cite{de2012automated} and Diekmann~\cite{diekmann2018dont} investigate error repair in LR grammars and more recently, Raselimo and Fischer use spectrum-based fault localization techniques~\cite{raselimo2021automatic}. Our approach can handle a more general class of context-free and bounded context-sensitive grammars and has a more theoretically rigorous grounding in language reachability~\cite{melski1997interconvertbility}. Consequently, it is much simpler and can scaled up using a GPU. Tradeoffs exist as usual, which are discussed in Sec.~\ref{sec:discussion}.

\section{Toy Example}

Suppose we are given the following context free grammar:

\begin{tidyinput}
S -> S and S | S or S | ( S ) | true | false | ! S(*@\caret{ }@*)
\end{tidyinput}

\noindent For reasons that will become clear in the following section, this is automatically rewritten into the equivalent grammar:

\begin{verbatim}
 F.! → !  ε+ → ε      S → false    F.and → and
 F.( → (  ε+ → ε+ ε+  S → F.! S      S.) → S F.)
 F.) → )   S → <S>    S → S or.S    or.S → F.or S
 F.ε → ε   S → true   S → S and.S  and.S → F.and S
F.or → or  S → S ε+   S → F.( S.)
\end{verbatim}

%\noindent We can visualize the CFG as either a graph or a matrix:
%
%\begin{figure}[H]
%    \includegraphics[width=3.5cm]{../figures/bool_arith_cfg_graph.png}
%    \hspace{20pt}
%    \includegraphics[width=3.5cm]{../figures/bool_arith_cfg_mat.bmp}
%\end{figure}

\noindent Given a string containing holes such as the one below, Tidyparse will return several completions in a few milliseconds:

\begin{tidyinput}
true _ _ _ ( false _ ( _ _ _ _ ! _ _ ) _ _ _ _(*@\caret{ }@*)
\end{tidyinput}

\begin{tidyoutput}
true (*@\hlorange{or}@*) (*@\hlorange{!}@*) ( false (*@\hlorange{or}@*) ( <S> (*@\hlorange{)}@*) or ! (*@\hlorange{<S>}@*) ) (*@\hlorange{or}@*) (*@\hlorange{<S>}@*)
true (*@\hlorange{or}@*) (*@\hlorange{!}@*) ( false (*@\hlorange{and}@*) ( <S> (*@\hlorange{)}@*) or ! (*@\hlorange{<S>}@*) ) (*@\hlorange{or}@*) (*@\hlorange{<S>}@*)
true (*@\hlorange{or}@*) (*@\hlorange{!}@*) ( false (*@\hlorange{and}@*) ( <S> (*@\hlorange{)}@*) and ! (*@\hlorange{<S>}@*) ) (*@\hlorange{or}@*) (*@\hlorange{<S>}@*)
true (*@\hlorange{or}@*) (*@\hlorange{!}@*) ( false (*@\hlorange{and}@*) ( <S> (*@\hlorange{)}@*) and ! (*@\hlorange{<S>}@*) ) (*@\hlorange{and}@*) (*@\hlorange{<S>}@*)
...
\end{tidyoutput}

\noindent Similarly, if provided with a string containing various errors, Tidyparse will return several suggestions how to fix it, where \hlgreen{green} is insertion, \hlorange{orange} is substitution and \hlred{red} is deletion.

\begin{tidyinput}
true and ( false or and true false(*@\caret{ }@*)
\end{tidyinput}

\begin{tidyoutput}
1.) true and ( false or (*@\hlorange{!}@*) true (*@\hlorange{)}@*)
2.) true and ( false or (*@\hlgreen{<S>}@*) and true (*@\hlorange{)}@*)
3.) true and ( false or (*@\hlorange{(}@*) true (*@\hlorange{)}@*) (*@\hlgreen{)}@*)
...
9.) true and ( false or (*@\hlgreen{!}@*) (*@\hlgreen{<S>}@*) (*@\hlgreen{)}@*) and true (*@\hlred{false} @*)
\end{tidyoutput}

\noindent In the following paper, we will describe how we built it.

\section{Matrix Theory}

Recall that a CFG is a quadruple consisting of terminals $(\Sigma)$, nonterminals $(V)$, productions $(P\colon V \rightarrow (V \mid \Sigma)^*)$, and a start symbol, $(S)$. It is a well-known fact that every CFG is reducible to \textit{Chomsky Normal Form}, $P'\colon V \rightarrow (V^2 \mid \Sigma)$, in which every production takes one of two forms, either $w \rightarrow xz$, or $w \rightarrow t$, where $w, x, z: V$ and $t: \Sigma$. For example, the CFG, $P:=\{S \rightarrow S S \mid ( S ) \mid ()\}$, corresponds to the CNF:\vspace{-3pt}

\begin{table}[H]
    \begin{tabular}{llll}
        $P'=\big\{\;S\rightarrow QR \mid SS \mid LR,$ & $L \rightarrow (,$ & $R \rightarrow ),$ & $Q\rightarrow LS\;\big\}$
    \end{tabular}
\end{table}\vspace{-8pt}

\noindent Given a CFG, $\mathcal{G}' : \langle \Sigma, V, P, S\rangle$ in CNF, we can construct a recognizer $R: \mathcal{G}' \rightarrow \Sigma^n \rightarrow \mathbb{B}$ for strings $\sigma: \Sigma^n$ as follows. Let $2^V$ be our domain, $0$ be $\varnothing$, $\oplus$ be $\cup$, and $\otimes$ be defined as:\vspace{-10pt}

\begin{align}
    X \otimes Z := \big\{\;w \mid \langle x, z\rangle \in X \times Z, (w\rightarrow xz) \in P\;\big\}
\end{align}

\noindent If we define $\sigma_r^{\shur} \coloneqq \{w \mid (w \rightarrow \sigma_r) \in P\}$, then initialize $M^0_{r+1=c}(\mathcal{G}', e) := \;\sigma_r^{\shur}$ and solve for the fixpoint $M^* = M + M^2$,\vspace{-10pt}

\begin{align*}
    M^0:=\begin{pNiceMatrix}[nullify-dots,xdots/line-style=loosely dotted]
        \varnothing & \sigma_1^\shri & \varnothing & \Cdots & \varnothing \\
        \Vdots      & \Ddots         & \Ddots      & \Ddots & \Vdots\\
                    &                &             &        & \varnothing\\
                    &                &             &        & \sigma_n^\shup \\
        \varnothing & \Cdots         &             &        & \varnothing
    \end{pNiceMatrix} &\Rightarrow M^* =
    \begin{pNiceMatrix}[nullify-dots,xdots/line-style=loosely dotted]
        \varnothing & \sigma_1^\shri & \Lambda & \Cdots & \Lambda^*_\sigma\\
        \Vdots      & \Ddots         & \Ddots  & \Ddots & \Vdots\\
                    &                &         &        & \Lambda\\
                    &                &         &        & \sigma_n^\shup \\
        \varnothing & \Cdots         &         &        & \varnothing
    \end{pNiceMatrix}
\end{align*}

\noindent we obtain the recognizer, $R(\mathcal{G}', \sigma) := S \in \Lambda^*_\sigma? \Leftrightarrow \sigma \in \mathcal{L}(\mathcal{G})?$

This decision procedure can be abstracted by lifting into the domain of bitvector variables, producing an algebraic expression for each scalar inhabitant of the northeasternmost bitvector $\Lambda^*_\sigma$, whose solutions correspond to valid parse forests for an incomplete string on the superdiagonal. Note that $\bigoplus_{c = 1}^n M_{r,c} \otimes M_{c,r}$ has cardinality bounded by $|V|$ and is thus representable as a fixed-length vector using the characteristic function, $\mathds{1}$. In particular, $\oplus, \otimes$ are redefined as $\boxplus, \boxtimes$ over bitvectors so the following diagram commutes,\footnote{Hereinafter, we use gray highlighting to distinguish between expressions containing only \highlight{\text{constants}} from those which may contain free variables.}

\begin{figure}[H]
    \adjustbox{scale=0.75,center}{%
        \[\begin{tikzcd}[row sep=large, column sep=huge]
              \langle\mathcal{G}', \highlight{\Sigma}^{n-1}\rangle \arrow[leftrightarrow, drrr, shorten=-1mm] & & [-135pt] & \vspace{20pt}\text{Set} \arrow[d, phantom] & \text{Bit} \arrow[d, phantom] & [-90pt] & \langle\mathcal{G}', \Sigma^{n-1}\rangle \arrow[drr, shorten=-2mm] & [-90pt] & \text{SAT} \arrow[d, phantom]\\[-30pt]
              \text{Rubix}  \arrow[rr, phantom] & & [-135pt] & M \times M \arrow[r, "\mathds{1}^{2^{n\times n}}", labels=above] \arrow[d, "\hspace{-13pt}\bigoplus\:\bigotimes"] & \mathbb{Z}_2^{|V|^{n\times n}} \times \mathbb{Z}_2^{|V|^{n\times n}} \arrow[d, "\hspace{-13.4pt}\highlight{+}\:\highlight{*}"] \arrow[l, "\mathds{1}^{-2^{n\times n}}", labels=below] \arrow[rrrr, rightarrowtail, "\varphi^{2^{n\times n}}", labels=above] & [-90pt] & & [-90pt] & \mathcal{M} \times \mathcal{M} \arrow[llll, rightharpoonup, shorten=1mm, "\varphi^{-2^{n\times n}}", labels=below] \arrow[d, "\hspace{-9pt}+\:\:\:*"] \\
              \text{Matrix} \arrow[rr, phantom] & & [-135pt] & 2^V \times 2^V \arrow[r, "\mathds{1}^{2}", labels=above] \arrow[d, "\hspace{-9pt}\oplus\:\otimes"] & \mathbb{Z}_2^{|V|} \times \mathbb{Z}_2^{|V|} \arrow[d, "\hspace{-15.8pt}\highlight{\boxplus}\:\highlight{\boxtimes}"] \arrow[l, "\mathds{1}^{-2}", labels=below] \arrow[rrrr, rightarrowtail, "\varphi^2", labels=above] & [-90pt] & & [-90pt] & \mathcal{V} \times \mathcal{V} \arrow[llll, rightharpoonup, shorten=1mm, "\varphi^{-2}", labels=below] \arrow[d, "\hspace{-9.5pt}\boxplus\:\boxtimes"] \arrow[u] \\
              \text{Vector} \arrow[rr, phantom] & & [-135pt] & 2^V \arrow[r, "\mathds{1}", labels=above] & \mathbb{Z}_2^{|V|} \arrow[l, "\mathds{1}^{-1}", labels=below] \arrow[rrrr, rightarrowtail, "\varphi", labels=above] & [-90pt] & & [-90pt] & \mathcal{V} \arrow[llll, rightharpoonup, shorten=1mm, "\varphi^{-1}", labels=below] \arrow[u]
        \end{tikzcd}\]
    }
\end{figure}

\noindent where $\mathcal{V}$ is a function $\mathbb{Z}_2^{|V|}\rightarrow\mathbb{Z}_2$. Note that while always possible to encode $\mathbb{Z}_2^{|V|} \rightarrow \mathcal{V}$ using the identity function, $\varphi^{-1}$ may not exist, as an arbitrary $\mathcal{V}$ might have zero, one, or in general, multiple solutions in $\mathbb{Z}_2^{|V|}$.

Full details of the bisimilarity between parsing and matrix multiplication can be found in Valiant~\cite{valiant1975general}, who shows its time complexity to be $\mathcal{O}(n^\omega)$ where $\omega$ is the matrix multiplication bound ($\omega < 2.77$), and Lee~\cite{lee2002fast}, who shows that speedups to Boolean matrix multiplication are realizable by CFL parsers. Assuming sparsity, this technique is typically linearithmic, and is shown to be highly efficient.

\subsection{Context-sensitive reachability}

It is well-known that the family of CFLs is not closed under intersection. For example, consider $\mathcal{L}_\cap := \mathcal{L}(\mathcal{G}_1) \cap \mathcal{L}(\mathcal{G}_1)$:

\begin{table}[H]
    \begin{tabular}{llll}
        $P_1 := \big\{\;S \rightarrow L R,$ & $L \rightarrow a b \mid a L b,$ & $R \rightarrow c \mid c R\;\big\}$\vspace{5pt}\\
        $P_2 := \big\{\;S \rightarrow L R,$ & $R \rightarrow b c \mid b R c,$ & $L \rightarrow a \mid a L\;\big\}$
    \end{tabular}
\end{table}

\noindent Note that $\mathcal{L}_\cap$ generates the language $\big\{\;a^d b^d c^d \mid d > 0\;\big\}$, which according to the pumping lemma is not context-free. We can encode $\bigcap_{i=1}^c \mathcal{L}(\mathcal{G}_i)$ as a polygonal prism with upper-triangular matrices adjoined to each rectangular face. More precisely, we intersect all terminals $\Sigma_\cap := \bigcap_{i=1}^c \Sigma_i$, then for each $t_\cap \in \Sigma_\cap$ and CFG, construct an equivalence class $E(t_\cap, \mathcal{G}_i) = \{ w_i \mid (w_i \rightarrow t_\cap) \in P_i\}$ and bind them together:\vspace{-5pt}

\begin{align}
    \bigwedge_{t\in\Sigma_\cap}\bigwedge_{j = 1}^{c-1}\bigwedge_{i=1}^{|\sigma|} E(t_{\cap}, \mathcal{G}_j) \equiv_{\sigma_i} E(t_{\cap}, \mathcal{G}_{j+1})
\end{align}
% Generated by cfl4_intersection.vox, open with https://voxelator.com/
\begin{figure}[H]
    \includegraphics[height=0.063\textwidth]{../figures/angle1.png}\hspace{-5pt}
    \includegraphics[height=0.063\textwidth]{../figures/angle2.png}\hspace{-5pt}
    \includegraphics[height=0.063\textwidth]{../figures/angle5.png}\hspace{-5pt}
    \includegraphics[height=0.063\textwidth]{../figures/angle3.png}\hspace{-3pt}
    \includegraphics[height=0.063\textwidth]{../figures/angle4.png}
    \caption{Orientations of a $\bigcap_{i = 1}^4 \mathcal{L}(\mathcal{G}_i) \cap \Sigma ^6$ configuration. As $c \rightarrow \infty$, this shape approximates a circular cone whose symmetric axis joins $\sigma_i$ with orthonormal unit productions $w_i \rightarrow t_\cap$, and $S_i \in \Lambda^*_{\sigma}?$ represented by the outermost bitvector inhabitants. Equations of this form are equiexpressive with the family of CSLs realizable by finite CFL intersection.}
\end{figure}


\subsection{Encoding CFG parsing as SAT solving}\label{sec:sat}

By allowing the matrix $M^*$ to contain bitvector variables representing holes in the string and nonterminal sets, we obtain a set of multilinear equations over $\mathbb{Z}_2$, whose solutions exactly correspond to the set of admissible repairs and their corresponding parse forests. Specifically, the repairs coincide with holes in the superdiagonal $M^*_{r+1 = c}$, and the parse forests occur along the upper-triangular entries $M^*_{r + 1 < c}$.

%We precompute the shadow of fully-resolved substrings before feeding it to the SAT solver. If the substring is known, we can simply compute this directly outside the SAT solver. Shaded regions are bitvector literals and light regions correspond to bitvector variables.

%We illustrate this fact in \S\ref{sec:error}:
%
%\begin{figure}[H]
%    \includegraphics[width=2cm]{../figures/parse1.png}
%    \includegraphics[width=2cm]{../figures/parse2.png}
%    \includegraphics[width=2cm]{../figures/parse3.png}
%    \includegraphics[width=2cm]{../figures/parse4.png}
%\end{figure}

\newcommand\ddd{\Ddots}
\newcommand\vdd{\Vdots}
\newcommand\cdd{\Cdots}
\newcommand\lds{\ldots}
\newcommand\vno{\varnothing}
\newcommand{\ts}[1]{\textsuperscript{#1}}
\newcommand\non{1\ts{st}}
\newcommand\ntw{2\ts{nd}}
\newcommand\nth{3\ts{rd}}
\newcommand\nfo{4\ts{th}}
\newcommand\nfi{5\ts{th}}
\newcommand\nsi{6\ts{th}}
\newcommand\nse{7\ts{th}}
\newcommand{\vs}[1]{\sigma_{#1}^{\shur}}
\newcommand\rcr{\rowcolor{black!15}}
\newcommand\rcw{\rowcolor{white}}
\newcommand\pcd{\cdot}
\newcommand\pcp{\phantom\cdot}
\newcommand\ppp{\phantom{\nse}}

\begin{align}
   M^* = \begin{pNiceArray}{>{\strut}ccccccc}[margin, extra-margin=2pt,colortbl-like, xdots/line-style=loosely dotted]
      \vno & \rcr \vs{1} &  \mathcal{L}_{1,3} & \mathcal{L}_{1,3} & \rcw \mathcal{V}_{1,4} & \cdd & \mathcal{V}_{1,n} \\
      \vdd & \ddd        &  \rcr\vs{2}        & \mathcal{L}_{2,3} & \rcw\vdd               &      & \vdd \\
           &             &                    & \rcr\vs{3}        & \rcw                   &      & \\
           &             &                    &                   & \mathcal{V}_{4,4}      &      & \\
           &             &                    &                   &                        & \ddd & \\
           &             &                    &                   &                        &      & \mathcal{V}_{n,n} \\
      \vno & \cdd        &                    &                   &                        &      & \vno
   \end{pNiceArray}
\end{align}

\noindent Depicted above is a SAT tensor representing \hlgray{$\sigma_1\:\sigma_2\:\sigma_3$}$\:\_\:\ldots\:\_$ where shaded regions demarcate known bitvector literals $\mathcal{L}_{r,c}$ (i.e., representing established nonterminal forests) and unshaded regions correspond to bitvector variables $\mathcal{V}_{r,c}$ (i.e., representing seeded nonterminal forests to be grown). Since $\mathcal{L}_{r,c}$ are fixed, we precompute them outside the SAT solver.

\subsection{Gradient estimation}\label{sec:dsi}

Now that we have a reliable method to fix \textit{localized} errors, $S: \mathcal{G} \times (\Sigma\cup\{\varepsilon, \texttt{\_}\})^n \rightarrow \{\Sigma^n\}\subseteq \mathcal{L}_\mathcal{G}$, given some unparseable string, i.e., $\err{\sigma_1\ldots\:\sigma_n}: \highlight{\Sigma}^n \cap\mathcal{L}(\mathcal{G})^c$, where should we put holes to obtain a parseable $\sigma' \in \mathcal{L}(\mathcal{G})$? One way to do so is by sampling sketch templates, $\bm{\sigma}:\Sigma^{n\pm q}\sim\Delta_{q}(\sigma)$ from the Levenshtein q-ball centered on $\sigma$, i.e., the space of all possible edits with Levenshtein distance $\leq q$, loosely analogous to a finite difference approximation. To admit variable-length edits, we first add an $\varepsilon^+$-production to each unit production:\vspace{5pt}

\begin{prooftree}
    \AxiomC{$\mathcal{G} \vdash \varepsilon \in \Sigma$}
    \RightLabel{$\varepsilon\textsc{-dup}$}
    \UnaryInfC{$\mathcal{G} \vdash (\varepsilon^+ \rightarrow \varepsilon \mid \varepsilon^+\:\varepsilon^+) \in P$}
\end{prooftree}

\begin{prooftree}
    \AxiomC{$\mathcal{G} \vdash (A \rightarrow B) \in P$}
    \RightLabel{$\varepsilon^+\textsc{-int}$}
    \UnaryInfC{$\mathcal{G} \vdash (A \rightarrow B\:\varepsilon^+ \mid \varepsilon^+\:B \mid B) \in P$}
\end{prooftree}

\noindent Next, suppose $U: \mathbb{Z}_2^{m\times m}$ is a matrix whose structure is shown in Eq.~\ref{eq:lfsr}, wherein $C$ is a primitive polynomial over $\mathbb{Z}_2^m$ with coefficients $C_{1\ldots m}$ and semiring operators $\oplus := \veebar, \otimes := \land$:\vspace{-5pt}

\begin{align}
    U^tV = \begin{pNiceMatrix}[nullify-dots,xdots/line-style=loosely dotted]
               C_1    & \cdd  &       &       & C_m \\
               \top   & \circ & \cdd  &       & \circ \\
               \circ  & \ddd  & \ddd  &       & \vdd \\
               \vdd   & \ddd  &       &       & \\
               \circ  & \cdd  & \circ & \top  & \circ
    \end{pNiceMatrix}^t
    \begin{pNiceMatrix}[nullify-dots,xdots/line-style=loosely dotted]
        V_1 \\
        \vdd\\
        \\
        \\
        V_m
    \end{pNiceMatrix}\label{eq:lfsr}
\end{align}

\noindent Since $C$ is primitive, the sequence $\mathbf{S} = (U^{0 \ldots 2^m-1}V)$ must have \textit{full periodicity}, i.e., for all $i, j \in[0, 2^m)$, ${\mathbf{S}_i = \mathbf{S}_j \Rightarrow i = j}$. To uniformly sample $\bm\sigma \sim \Sigma^d$ without replacement, we form an injection $\mathbb{Z}_2^m\rightharpoonup\stirlingii{n}{d}\footnote[2]{\text{Where $\stirlingii{n}{d}$ is used to denote the set of all $d$-element subsets of $\{1,\ldots, n\}$.}}\times\Sigma_\varepsilon^{2d}$ using a combinatorial number system, cycle over $\mathbf{S}$, then discard samples which have no witness in $\stirlingii{n}{d}\times\Sigma_\varepsilon^{2d}$. This method requires $\widetilde{\mathcal O}(1)$ per sample and $\widetilde{\mathcal O}\left({n \choose d}|\Sigma + 1|^{2d}\right)$ to exhaustively search through $\stirlingii{n}{d}\times\Sigma_\varepsilon^d$.

Finally, to sample $\bm{\sigma}\sim\Delta_{q}(\sigma)$, we enumerate sketch templates $H(\sigma, i) = \sigma_{1\ldots i-1}\:\text{\_ \_}\:\sigma_{i+1\ldots n}$ for each $i \in \cdot \in \stirlingii{n}{d}$ and $d \in 1\ldots q$, then solve for $\mathcal{M}_{\bm\sigma}^*$. If $S \in \Lambda^*_{\bm\sigma}?$ has a solution, each edit in each $\sigma' \in \bm\sigma$ will match one of seven patterns:\vspace{-10pt}

\begin{align*}
    \text{Deletion}&=\begin{cases}
      \sigma_{1}\:\ldots\:\text{\hlred{$\gamma_1$}\:\hlred{$\gamma_2$}}\:\ldots\:\sigma_n\hspace{0.2cm}\gamma_{1, 2} = \varepsilon\label{eq:del}
    \end{cases}\\
    \text{Substitution}&=\begin{cases}
      \sigma_{1}\:\ldots\:\text{\hlorange{$\gamma_1$}\:\hlred{$\gamma_2$}}\:\ldots\:\sigma_n\hspace{0.2cm}\gamma_1 \neq \varepsilon \land \gamma_2 = \varepsilon\\
      \sigma_{1}\:\ldots\:\text{\hlred{$\gamma_1$}\:\hlorange{$\gamma_2$}}\:\ldots\:\sigma_n\hspace{0.2cm}\gamma_1 = \varepsilon \land \gamma_2 \neq \varepsilon\\
      \sigma_{1}\:\ldots\: \text{\hlorange{$\gamma_1$}\:\hlorange{$\gamma_2$}}\:\ldots\:\sigma_n\hspace{0.2cm}\{\gamma_1, \gamma_2\}\cap\{\varepsilon, \sigma_i\} = \varnothing
    \end{cases}\\
    \text{Insertion}&=\begin{cases}
      \sigma_{1}\:\ldots\: \text{\hlgreen{$\gamma_1$}\:\hlorange{$\gamma_2$}}\:\ldots\:\sigma_n\hspace{0.2cm}\gamma_1 = \sigma_i \land \gamma_2 \notin \{\varepsilon,  \sigma_i\}\label{eq:ins2}\\
      \sigma_{1}\:\ldots\: \text{\hlorange{$\gamma_1$}\:\hlgreen{$\gamma_2$}}\:\ldots\:\sigma_n\hspace{0.2cm}\gamma_1 \notin \{\varepsilon, \sigma_i\} \land \gamma_2 = \sigma_i\label{eq:ins1}\\
      \sigma_{1}\:\ldots\: \text{\hlgreen{$\gamma_1$}\:\hlgreen{$\gamma_2$}}\:\ldots\:\sigma_n\hspace{0.2cm}\gamma_{1,2} = \sigma_i\label{eq:copy}
    \end{cases}
\end{align*}

\section{Realtime Error Correction}\label{sec:holes}

Assuming $d$ holes, there are ${n \choose d}$ possible hole configurations (HCs), each with $(|\Sigma| + 1)^{2d}$ possible repairs. In practice, depending on $n$ and $d$, this space can be intractable to search through exhaustively, and a uniform distribution may be sample-inefficient, so to facilitate real-time assistance we prioritize likely repairs according to an eight-step procedure:

\begin{enumerate}
    \item Fetch the most recent CFG and string from the editor.
    \item Exclude parsable substrings from hollowing.
    \item Lazily enumerate all $\mathbf{\sigma}$ of increasing length.
    \item Sample $\bm{\sigma}\sim\Delta_{q}(\sigma)$ without replacement using Eq.~\ref{eq:lfsr}.
    \item Prioritize HCs first by distance to caret index, then by Earthmover's distance to a set of suspicious indices.\footnote{These locations can be supplied by local edit history or using tokenwise perplexity from a neural language model. Once a new repair is discovered, it is immediately displayed. Incoming keystrokes interrupt and reset the solving process.}
    \item Translate HCs to sketch templates using~\S\ref{sec:dsi}.
    \item Feed sketch templates to an incremental SAT solver.
    \item Decode and rerank models by Levenshtein distance.
\end{enumerate}

For example, suppose we have the following distribution over some string, $\Sigma^{90}$, say given by the historical caret position or a neural language model. Morally, we know there are some errors near $\sigma_{17, 45, 72}$ and want to prioritize edits nearby those locations.

\hspace{-0.3cm}\begin{tikzpicture}[scale=0.4]
  \begin{axis}[x=2cm, y=2cm, every axis plot post/.append style={mark=none,domain=-2:7.5,samples=50,smooth},
    axis x line*=bottom, % no box around the plot, only x and y axis
    ticks=none,
    y axis line style={draw=none},
    xticklabels={,,},
    enlargelimits=upper] % extend the axes a bit to the right and top
    \addplot[name path=F] {gauss(0.0,0.4)};
    \addplot[name path=G] {gauss(3.0,0.5)};
    \addplot[name path=H] {gauss(6.0,0.3)};
    \addplot[name path=N] {nil(0)};
    \addplot[pattern=vertical lines, pattern color=gray!50]fill between[of=F and N, soft clip={domain=-3:1}];
    \addplot[pattern=vertical lines, pattern color=gray!50]fill between[of=G and N, soft clip={domain=1:5}];
    \addplot[pattern=vertical lines, pattern color=gray!50]fill between[of=H and N, soft clip={domain=4:7.5}];
  \end{axis}
  \node [xshift=4.1cm, yshift=-7pt] {\footnotesize $\sigma_1\hspace{0.5cm}\sigma_{10}\err{\hspace{0.5cm}\sigma_{20}}\hspace{0.5cm}\sigma_{30}\hspace{0.5cm}\err{\sigma_{40}\hspace{0.5cm}\sigma_{50}}\hspace{0.5cm}\sigma_{60}\hspace{0.5cm}\err{\sigma_{70}\hspace{0.3cm}}\hspace{0.2cm}\sigma_{80}\hspace{0.5cm}\sigma_{90}$};
%  \node [xshift=142pt, yshift=7pt] {\footnotesize $P_2(X)$};
%  \node [xshift=227pt, yshift=7pt] {\footnotesize $P_3(X)$};
\end{tikzpicture}

We can sample for tokens nearby using the Kantorovich--Rubinstein (KR) metric over the Levenshtein q-ball, $\Delta_q(\sigma)$. Viewed as an optimal transport problem, $\delta_{KR}$ minimizes over $\Pi$, the set of all mass-conserving transportation plans between two probability distributions $\mu$ and $\nu$, on a sample space $\Omega$:

\begin{align}
    \delta_{\textsc{KR}}(\mu, \nu) := \inf_{\pi\in \Pi(\mu, \nu)}\int_{\Omega\times \Omega} \delta(x, y)d\pi(x, y)
\end{align}

We can think of this procedure as a moment-matching procedure between some joint distribution over the edit locations and a cost model (e.g., finger travel distance on a physical keyboard in the case of typo correction, weighted Levenshtein distance, or stochastic contextual edit distance). Morally, we want to prioritize sketch templates which are nearby probable errors and repairs which are, in some sense, ``natural'' for a hole and its surrounding context.

Not only is Tidyparse capable of suggesting repairs to incorrect strings, it can also return partial trees for strings which do not parse. This is often helpful for debugging purposes.


\pagebreak
\section{Error Recovery}\label{sec:error}

Unlike classical parsers which require special rules for error recovery, if the input string does not parse, Tidyparse can return partial subtrees. If no solution exists, the upper triangular entries will appear as a jagged-shaped ridge whose peaks represent the roots of parsable ASTs. These provide a natural debugging environment to aid the repair process.
Occasionally, it is not possible to decode a full tree. In a typical parser, error recovery requires special tricks. Here, we simply analyze the structure of the matrix $M$ to decode the parseable subtrees:

\begin{figure}[H]
    \hspace{-0.5cm}\begin{minipage}[l]{6cm}
      \[
          \begin{NiceMatrix}
              \leftarrow & \nse & \nsi & \nfi & \nfo & \nth & \ntw & \non & \leftarrow & \ppp \\
                         &      & \ddd & \ddd & \ddd & \ddd & \ddd & \ddd & \ddd & \ppp \\
          \sigma_1^\shri & \cdd &      & A    &      &      &      &      &      & \ppp \\
                    \vno & \ddd &  T_A & \vdd &      &      &      &      &      & \ppp \\
                    \vdd & \ddd &      & \pcd & \cdd &      & B    &      &      & \ppp \\
                         &      &      &      &      & T_B  & \vdd &      &      & \ppp \\
                         &      &      &      &      &      & \pcd & \cdd &      & C    \\
                         &      &      &      &      &      &      &      & T_C  & \vdd \\
                         &      &      &      &      &      &      & \text{\emoji{cross-mark}} &      & \\
                         &      &      &      &      &      &      &      &      & \\
                         &      &      &      &      &      &      &      &      & \\
                         &      &      &      &      &      &      &      & \ppp & \sigma_n^\shup \\
                    \vno & \cdd &      &      &      &      &      &      & \vno &
          \end{NiceMatrix}
      \]
    \end{minipage}
    \hspace{1cm}

    \caption{Peaks along the UT matrix ridge correspond to maximally parseable substrings. By recursing over upper diagonals of decreasing elevation and discarding all subtrees that fall under the shadow of another's canopy, we can recover the partial subtrees. The example depicted above contains three such branches, rooted at nonterminals $C, B, A$.}\label{fig:peaks}
\end{figure}

\noindent These branches correspond to peaks on the upper triangular (UT) matrix ridge. As depicted in Fig.~\ref{fig:peaks}, we traverse the peaks by decreasing elevation to collect partial AST branches.

\begin{tidyinput}
(*@\err{true and true ! and false or true ! true and false}\caret{ }@*)
\end{tidyinput}

\begin{verbatim}
 Parseable subtrees (3 leaves / 2 branches):
\end{verbatim}
\noindent\hspace{0.64cm}\emoji{herb}\hspace{1.70cm}\emoji{herb}\hspace{1.98cm}\emoji{herb}\vspace{-5pt}
\begin{verbatim}
    └── ! [3]   └── and [4]   └── or [6]
\end{verbatim}
\hspace{0.63cm}\emoji{herb}\hspace{3.4cm}\emoji{herb}\vspace{-5pt}
\begin{verbatim}
    └── S [0..2]          └── S [8..11]
        ├── true [0]          ├── S [8..9]
        ├── and [1]           │   ├── ! [8]
        └── true [2]          │   └── true [9]
                              ├── and [10]
                              └── false [11]
\end{verbatim}

\section{Tree Denormalization}

% https://www.ling.upenn.edu/advice/latex/qtree/qtreenotes.pdf
% https://cpb-us-w2.wpmucdn.com/campuspress.yale.edu/dist/0/119/files/2014/12/sec-10.17-drawing-arrows-2ek9r2b.pdf

Our parser emits a binary forest consisting of parse trees for the candidate string according to the CNF grammar, however this forest contains many so-called \textit{Krummholz}, or \textit{flag trees}, often found clinging to windy ridges and mountainsides.

\begin{figure}[H]
\resizebox{.50\textwidth}{!}{
\begin{tabular}{ll}
    \Tree [.\texttt{S} \tikz\node(v1){\texttt{true}} [.$\ccancel{\texttt{and.S}}$ \tikz\node(v3){\texttt{and}} [.\texttt{S} \tikz\node(v5){\texttt{(}} [.$\ccancel{\texttt{S.)}}$ [.\texttt{S} \tikz\node(v9){\texttt{false}} [.$\ccancel{\texttt{or.S}}$ \tikz\node(v11){\texttt{or}} [.\texttt{S} \texttt{!} \texttt{true} ] ] ] \tikz\node(v7){\texttt{)}} ] ] ] ]
%    \Tree [.S [.NP John ] [.VP [.\tikz\node(v1){V}; sleeps ] ] ]
    \hspace{-2cm}
    &
    \Tree [.\texttt{S} \tikz\node(v2){\texttt{true}} \tikz\node(v4){\texttt{and}} [.\texttt{S} \tikz\node(v6){\texttt{(}} [.\texttt{S} \tikz\node(v10){\texttt{false}} \tikz\node(v12){\texttt{or}} [.\texttt{S} \texttt{!} \texttt{true} ] ] \tikz\node(v8){\texttt{)}} ] ]\\\\
%    \Tree [.\tikz\node(v2){V}; [.\tikz\node(v3){V}; ] [.Adv {a lot} ] ]
    \hspace{1cm}\huge{Pre-Denormalization} & \hspace{3cm}\huge{Post-Denormalization}
\end{tabular}
\begin{tikzpicture}[overlay]
%    \draw [red,dashed,-stealth] (v1) to[bend left] (v2);
    \draw [red,dashed,-stealth] (v3) to[bend left] (v4);
%    \draw [red,dashed,-stealth] (v5) to[bend left] (v6);
    \draw [red,dashed,-stealth] (v7) to[bend left] (v8);
%    \draw [red,dashed,-stealth] (v9) to[bend right] (v10);
    \draw [red,dashed,-stealth] (v11) to[bend right] (v12);
\end{tikzpicture}
}
%    \caption{Result of applying Algorithm~\ref{alg:cap} to the tree obtained by parsing the string: \texttt{true and ( false or ! true )}.}
\end{figure}\vspace{-10pt}
\begin{algorithm}
    \caption{Rewrite procedure for tree denormalization}\label{alg:cap}
    \begin{algorithmic}
        \Procedure{Denormalize}{\texttt{t: Tree}}
            \State $\texttt{stems} \leftarrow \{\:\textsc{Denormalize}(\texttt{c}) \mid \texttt{c} \in \texttt{t.children}\:\}$
            \If{$\texttt{t.root} \in V_{\mathcal{G}'} \setminus V_{\mathcal{G}}$}
                \State \textbf{return } \texttt{stems} \Comment{Drop synthetic nonterminals.}
            \Else\Comment{Graft the denormalized children on root.}
                \State \textbf{return } $\{\:\texttt{Tree(root, stems)}\:\}$
            \EndIf
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

\noindent To recover a parse tree congruent with the user-specified grammar, we prune all synthetic nodes and graft their stems onto the grandparent via a simple recursive procedure (Alg.~\ref{alg:cap}).%, which is used to denormalize both complete and partial ASTs (cf. \S~\ref{sec:error}) alike.

\section{Practical Example}

Tidyparse accepts any context-free grammar -- this can be either provided by the user or ingested from a BNF-like specification. The following is a slightly more complex grammar, designed to approximate the OCaml grammar. We use the \texttt{---} delimiter to separate the grammar from the example:

\begin{tidyinput}
S -> A | V | ( X , X ) | X X | ( X )
A -> Fun | F | L | L in X
Fun -> fun V (*@`@*)->(*@`@*) X
F -> if X then X else X
L -> let V = X | let rec V = X
V -> Vexp | ( Vexp ) | Vexp Vexp
Vexp -> VarName | FunName | Vexp VO Vexp
Vexp -> ( VarName , VarName ) | Vexp Vexp
VarName -> a | b | c | d | e | ... | z
FunName -> foldright | map | filter
VO ->  + | - | * | / | > | = | < | (*@`@*)||(*@`@*) | &&
---
let curry f = ( fun x y -> f ( _ _ _(*@\caret{ }@*)) )
\end{tidyinput}
\begin{tidyoutput}
let curry f = ( fun x y -> f ( (*@\hlorange{<X>}@*) ) )
let curry f = ( fun x y -> f ( (*@\hlorange{<FunName>}@*) ) )
let curry f = ( fun x y -> f ( (*@\hlorange{curry}@*) (*@\hlorange{<X>}@*) ) )
...
\end{tidyoutput}

\subsection{Context-sensitive languages}

Many programming languages exhibit either lexical or syntactic context-sensitivity, e.g., Python indentation. Tidyparse can analyze such languages using finite CFL-intersection, allowing it to generalize to a broader family of languages:

\begin{tidyinput}
S -> L R                  S -> L R
L -> a b | a L b          R -> b c | b R c
R -> c | c R              L -> a | a L
\end{tidyinput}

\subsection{Grammar Assistance}

Tidyparse uses a CFG to parse the CFG, so it can provide assistance while the user is designing the CFG. For example, if the CFG does not parse, it will suggest possible fixes. In the future, we intend to use this functionality to perform example-based codesign and grammar induction.

\begin{tidyinput}
B -> true | false | (*@\caret{ }@*)
\end{tidyinput}
\begin{tidyoutput}
B -> true | false (*@\hlred{ }@*)
B -> true | false (*@\hlorange{<RHS>}@*)
B -> true | false | (*@\hlgreen{<RHS>}@*)
...
\end{tidyoutput}

\subsection{Interactive Nonterminal Expansion}

Users can interactively build up a complex expression by placing the caret over a placeholder they wish to expand,

\begin{tidyinput}
if <(*@\caret{V}@*)exp> X then <Vexp> else <Vexp>
\end{tidyinput}

\noindent then invoking Tidyparse by pressing \keys{\ctrl + \SPACE}, to receive a list of expressions consistient with the grammar:

\begin{tidyoutput}
if (*@\hlorange{map}@*) X then <Vexp> else <Vexp>
if (*@\hlorange{uncurry}@*) X then <Vexp> else <Vexp>
if (*@\hlorange{foldright}@*) X then <Vexp> else <Vexp>
...
\end{tidyoutput}

%There are some more examples too.
%
%The line between parsing and computation is blurry.

\pagebreak
\section{Latency Benchmark}

In the following benchmarks, we measure the wall clock time required to synthesize solutions to length-50 strings sampled from various Dyck languages, where Dyck-n is the Dyck language containing n types of balanced parentheses.

\begin{tidyinput}
D1 -> () | ( D1 ) | D1 D1
D2 -> D1 | [ ] | ( D2 ) | [ D2 ] | D2 D2
D3 -> D2 | { } | ( D3 ) | [ D3 ] | { D3 } | D3 D3
\end{tidyinput}

\noindent In the first experiment, we sample a random valid string $\sigma \sim \Sigma^{50} \cap \mathcal{L}_{\text{Dyck-n}}$, then replace a fixed number tokens with holes and measure the average time taken to decode ten syntactically-admissible repairs across 100 trial runs.

\begin{tikzpicture}
  \begin{axis}[
      width=8.3cm,
    title={\hspace{-1cm}\textbf{Error correction time with known locations}},
    ybar,
    bar width=4pt,
    xlabel={Number of holes},
    ylabel={ms to synthesize 10 repairs},
    xtick=data,
    axis x line*=bottom,
    axis y line*=left,
    ytick pos=left,
    xticklabels from table={\loctimings}{holes},
    ymajorgrids,
    legend pos=north west,
    error bars/y dir=both,
    error bars/y explicit
  ]
    \addplot table [x expr=\coordindex, y=d1, y error=d1err]{\loctimings};
    \addplot table [x expr=\coordindex, y=d2, y error=d2err]{\loctimings};
    \addplot table [x expr=\coordindex, y=d3, y error=d3err]{\loctimings};
    \addplot table [x expr=\coordindex, y=d4, y error=d4err]{\loctimings};
    \legend{Dyck-1, Dyck-2, Dyck-3, Dyck-4}
  \end{axis}
\end{tikzpicture}

\noindent In the second experiment, we sample a random valid string as before, but delete p tokens at random and rather than provide the location(s), ask our model to solve for both the location(s) and repair by sampling uniformly from all n-token HCs, then measure the total time required to decode the first admissible repair. Note the the logarithmic scale on the y-axis.

\begin{tikzpicture}
    \begin{axis}[
        width=8.3cm,
        height=6.6cm,
        title={\hspace{-1cm}\textbf{Error correction time with unknown locations}},
        ybar,
        bar width=20pt,
        xlabel={Number of errors},
        ylabel={ms to synthesize 1 repair},
        xtick=data,
        axis x line*=bottom,
        axis y line*=left,
        enlarge x limits={abs=0.5},
        ymode=log,
        ytick pos=left,
        xticklabels from table={\unloctimings}{errors},
        ymajorgrids,
        legend pos=north west,
        error bars/y dir=both,
        error bars/y explicit
    ]
        \addplot table [x expr=\coordindex, y=d1]{\unloctimings};
        \addplot table [x expr=\coordindex, y=d2]{\unloctimings};
        \addplot table [x expr=\coordindex, y=d3]{\unloctimings};
        \legend{Dyck-1, Dyck-2, Dyck-3}
    \end{axis}
\end{tikzpicture}

\section{Accuracy Benchmark}

We analyze synthetic errors in Java and Python.

We also compare with the Break-it-fix-it (BIFI) dataset~\cite{yasunaga2021break}.

\section{Discussion}\label{sec:discussion}

While error correction with a few errors is tolerable, latency can vary depending on many factors including string length and grammar size. If errors are known to be concentrated in specific locations, such as the beginning or end of a string, then latency is typically below 500ms. Should errors occur uniformly at random, admissible repairs can take longer to discover, however these scenarios are unusual in our experience. We observe that errors are typically concentrated nearby historical edit locations, which can be retrieved from the IDE or version control. Further optimizations that reduce the total number of repairs checked are possible by eliminating improbable sketch templates.

Tidyparse in its current form has a number of technical shortcomings: firstly it does not incorporate any neural language modeling technology at present, an omission we hope to address in the near future. Training a language model to predict likely repair locations and rank admissible results could lead to lower overall latency and more natural repairs.

Secondly, our current method generates sketch templates using a na\"ive enumerative search, feeding them individually to the SAT solver, which has the tendency to duplicate prior work and introduces unnecessary thrashing. Considering recent extensions of Boolean matrix-based parsing to linear context-free rewriting systems (LCFRS)~\cite{cohen2016parsing}, it may be feasible to search through these edits within the SAT solver, leading to yet unrealized and possibly significant speedups.

Lastly and perhaps most significantly, Tidyparse does not incorporate any semantic constraints, so its repairs while syntactically admissible, are not guaranteed to be semantically valid. We note however, that it is possible to encode type-based semantic constraints into the solver and intend to explore this direction more fully in future work.

Although not intended to be a dedicated parser and we make no attempt to rigorously compare parsing latency, parsing valid strings with Tidyparse is typically competitive with classical parsing methods. Our primary motivation is to facilitate the usability and explainability of parsing with errors. We envision three primary use cases: (1) helping novice programmers become more quickly familiar with a new programming language (2) autocorrecting common typos among proficient but forgetful programmers and (3) as a prototyping tool for PL educators and designers.

Featuring a grammar editor and built-in SAT solver, Tidyparse helps developers navigate the language design space, visualize syntax trees, debug parsing errors and quickly generate simple examples and counterexamples for testing. Although the algorithm may seem esoteric at first glance, in our experience it is much more interpretable than classical parsers, which exhibit poor error-recovery and diagnostics.

\section{Conclusion}

Tidyparse accepts a CFG and a string to parse. If the string is valid, it returns the parse forest, otherwise, it returns a set of repairs, ordered by their Levenshtein edit distance to the invalid string. Our method compiles each CFG and candidate string onto a matrix dynamical system using an extended version of Valiant's construction and solves for its fixedpoints using an incremental SAT solver. This approach to parsing has many advantages, enabling us to repair syntax errors, correct typos and generate parse trees for incomplete strings. By allowing the string to contain holes, repairs can contain either concrete tokens or nonterminals, which can be manually expanded by the user or a neural-guided search procedure. From a theoretical standpoint, this technique is particularly amenable to neural program synthesis and repair, naturally integrating with the masked-language-modeling task (MLM) used by transformer-based neural language models.

From a practical standpoint, we have implemented our approach as an IDE plugin and demonstrated its viability as a tool for live programming. Tidyparse is capable of generating repairs for invalid code in a range of toy languages. We plan to continue expanding its grammar and autocorrection functionality to cover a broader range of languages and hope to conduct a more thorough user study to validate its effectiveness in the near future. Further examples can be found at our GitHub repository: \url{https://github.com/breandan/tidyparse}
%\begin{itemize}
%\item Error correction.
%\item Program repair.
%\item Program synthesis.
%\item Parsing with holes.
%\item Naturally integrates with masked language model (MLM)-based neural program repair.
%\item Parsing with natural error recovery.
%\item Helps to facilitate language learning.
%\item GPU acceleration.
%\end{itemize}

\section{Acknowledgements}
The first author would like to thank his co-advisor Xujie Si for providing many helpful suggestions during the development of this project, including the optimized fixpoint, test cases, and tree denomalization procedure. In addition, the authors extend their thanks to Nghi Bui at FPT Software for early feedback on the IDE plugin, Zhixin Xiong for contributing the OCaml grammar, Brigitte Pientka for asking the crucial question, ``Where do you put the holes?'', and Ori Roth for providing helpful comments on an early draft of this paper.
\bibliography{../bib/acmart}
\end{document}