%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[sigplan,10pt,review,anonymous]{acmart}
%\settopmatter{printfolios=false,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[sigplan,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[sigplan,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[sigplan,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[sigplan,nonacm]{acmart}
\documentclass[sigplan,review,anonymous,acmsmall]{acmart}\settopmatter{printfolios=false,printccs=false,printacmref=false}


%% Conference information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmConference[PLDI'23]{ACM SIGPLAN Conference on Programming Language Design and Implementation}{June 21, 2023}{Orlando, FL, USA}
%\acmYear{2018}
%\acmISBN{} % \acmISBN{978-x-xxxx-xxxx-x/YY/MM}
%\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
%\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{acmart}

\input{preamble.tex}
\begin{document}

%% Title information
    \title{Syntacic Error Correction as Idempotent Matrix Completion}
    \begin{abstract}
        Tidyparse is a program synthesizer that performs real-time error correction for context-free languages.
        Given both an arbitrary context-free grammar (CFG) and an invalid string, the tool lazily generates admissible repairs whilst the author is typing, ranked by Levenshtein edit distance. Repairs are guaranteed to be complete, grammatically consistent and minimal.
        Tidyparse is the first system of its kind offering these guarantees in a real-time editor. To accelerate code completion, we design and implement a novel incremental parser-synthesizer that transforms CFGs onto a dynamical system over finite field arithmetic, enabling us to suggest syntax repairs in-between keystrokes.
    \end{abstract}


    \maketitle

    \section{Introduction}

    Modern research on error correction can be traced back to the early days of coding theory, when researchers designed \textit{error-correcting codes} (ECCs) to denoise transmission errors induced by external interference, whether due to collision with a high-energy proton, manipulation by an adversary or some typographical mistake. In this context, \textit{code} can be any logical representation for communicating information between two parties (such as a human and a computer), and an ECC is a carefully-designed code which ensures that even if some portion of the message should be corrupted through accidental or intentional means, one can still recover the original message by solving a linear system of equations. In particular, we frame our work inside the context of errors arising from human factors in computer programming.

    In programming, most such errors initially manifest as syntax errors, and though often cosmetic, manual repair can present a significant challenge for novice programmers. The ECC problem may be refined by introducing a language, $\mathcal{L} \subset \Sigma^*$ and considering admissible edits transforming an arbitrary string, $s \in \Sigma^*$ into a string, $s'\in\mathcal{L}$. Known as \textit{error-correcting parsing} (ECP), this problem was well-studied in the early parsing literature, cf. Aho and Peterson~\cite{aho1972minimum}, but fell out of favor for many years, perhaps due to its perceived complexity. By considering only minimal-length edits, ECP can be reduced to the so-called \textit{language edit distance} (LED) problem, recently shown to be subcubic~\cite{bringmann2019truly}, suggesting its possible tractability. Previous results on ECP and LED were primarily of a theoretical nature, but now, thanks to our contributions, we have finally realized a practical prototype.

%String constraints
%
%Word equations

    \section{Toy Example}

    Suppose we are given the following context-free grammar:

\begin{tidyinput}
S -> S and S | S or S | ( S ) | true | false | ! S(*@\caret{ }@*)
\end{tidyinput}

    \noindent For reasons that will become clear in the following section, this is automatically rewritten into the equivalent grammar:

    \begin{verbatim}
 F.! → !  ε+ → ε      S → false    F.and → and
 F.( → (  ε+ → ε+ ε+  S → F.! S      S.) → S F.)
 F.) → )   S → <S>    S → S or.S    or.S → F.or S
 F.ε → ε   S → true   S → S and.S  and.S → F.and S
F.or → or  S → S ε+   S → F.( S.)
    \end{verbatim}

%\noindent We can visualize the CFG as either a graph or a matrix:
%
%\begin{figure}[H]
%    \includegraphics[width=3.5cm]{../figures/bool_arith_cfg_graph.png}
%    \hspace{20pt}
%    \includegraphics[width=3.5cm]{../figures/bool_arith_cfg_mat.bmp}
%\end{figure}

    \noindent Given a string containing holes such as the one below, Tidyparse will return several completions in a few milliseconds:

\begin{tidyinput}
true _ _ _ ( false _ ( _ _ _ _ ! _ _ ) _ _ _ _(*@\caret{ }@*)
\end{tidyinput}

\begin{tidyoutput}
true (*@\hlorange{or}@*) (*@\hlorange{!}@*) ( false (*@\hlorange{or}@*) ( <S> (*@\hlorange{)}@*) or ! (*@\hlorange{<S>}@*) ) (*@\hlorange{or}@*) (*@\hlorange{<S>}@*)
true (*@\hlorange{or}@*) (*@\hlorange{!}@*) ( false (*@\hlorange{and}@*) ( <S> (*@\hlorange{)}@*) or ! (*@\hlorange{<S>}@*) ) (*@\hlorange{or}@*) (*@\hlorange{<S>}@*)
true (*@\hlorange{or}@*) (*@\hlorange{!}@*) ( false (*@\hlorange{and}@*) ( <S> (*@\hlorange{)}@*) and ! (*@\hlorange{<S>}@*) ) (*@\hlorange{or}@*) (*@\hlorange{<S>}@*)
true (*@\hlorange{or}@*) (*@\hlorange{!}@*) ( false (*@\hlorange{and}@*) ( <S> (*@\hlorange{)}@*) and ! (*@\hlorange{<S>}@*) ) (*@\hlorange{and}@*) (*@\hlorange{<S>}@*)
...
\end{tidyoutput}

    \noindent Similarly, if provided with a string containing various errors, Tidyparse will return several suggestions how to fix it, where \hlgreen{green} is insertion, \hlorange{orange} is substitution and \hlred{red} is deletion.

\begin{tidyinput}
true and ( false or and true false(*@\caret{ }@*)
\end{tidyinput}

\begin{tidyoutput}
1.) true and ( false or (*@\hlorange{!}@*) true (*@\hlorange{)}@*)
2.) true and ( false or (*@\hlgreen{<S>}@*) and true (*@\hlorange{)}@*)
3.) true and ( false or (*@\hlorange{(}@*) true (*@\hlorange{)}@*) (*@\hlgreen{)}@*)
...
9.) true and ( false or (*@\hlgreen{!}@*) (*@\hlgreen{<S>}@*) (*@\hlgreen{)}@*) and true (*@\hlred{false} @*)
\end{tidyoutput}

    \noindent In the following paper, we will describe how we built it.

    \section{Matrix Theory}

    We recall that a CFG is a quadruple consisting of terminals, $\Sigma$, nonterminals, $V$, productions, $P: V \rightarrow (V \mid \Sigma)^*$, and the start symbol, $S$. It is a well-known fact that every CFG can be reduced to \textit{Chomsky Normal Form} (CNF), $P': V \rightarrow (V^2 \mid \Sigma)$, in which every production takes one of two forms, either $v_0 \rightarrow v_1 v_2$, or $v_0 \rightarrow \sigma$, where $v_{0, 1, 2}: V$ and $\sigma: \Sigma$. For example, we can rewrite the CFG $\{S \rightarrow S S \mid ( S ) \mid ()\}$, into CNF as:

    \[
        \{S\rightarrow XR \mid SS \mid LR,\; L \rightarrow (,\; R \rightarrow ),\; X\rightarrow LS\}
    \]

    \noindent Given a CFG, $\mathcal{G}' : \langle \Sigma, V, P, S\rangle$ in CNF, we can construct a recognizer $R_{\mathcal{G}'}: \Sigma^n \rightarrow \mathbb{B}$ for strings $\sigma: \Sigma^n$ as follows. Let $\mathcal P(V)$ be our domain, $0$ be $\vno$, $\oplus$ be $\cup$, and $\otimes$ be defined as:

    \begin{align}
        a \otimes b := \{C \mid \langle A, B\rangle \in a \times b, (C\rightarrow AB) \in P\}
    \end{align}

    \noindent We initialize $\mathbf{M}^0_{r,c}(\mathcal{G}', \sigma) \coloneqq \{V \mid c = r + 1, (V \rightarrow \sigma_r) \in P\}$ and search for $\mathbf{M}^*$ via fixpoint iteration,

    \newcommand\ddd{\Ddots}
    \newcommand\vdd{\Vdots}
    \newcommand\cdd{\Cdots}
    \newcommand\lds{\ldots}
    \newcommand\vno{\varnothing}

    \begin{align}
        \mathbf{M}^* = \begin{pNiceMatrix}[nullify-dots,xdots/line-style=loosely dotted]
                   \vno & \{V\}_{\sigma_1} & \cdd                   &                            & \mathcal{T} \\
                   \vdd & \ddd             & \Ddots[shorten=-0.1cm] & \phantom{\{V\}_{\sigma_2}} & \vdd \\
                        &                  &                        &                            & \\
                        &                  &                        &                            & \{V\}_{\sigma_n} \\
                   \vno & \cdd             &                        &                            & \vno
        \end{pNiceMatrix}\label{eq:fpm}
    \end{align}

    \noindent where $\mathbf{M}^*$ is the least solution to $\mathbf{M} = \mathbf{M} + \mathbf{M}^2$. The recognizer is defined as: $S \in \mathcal{T}? \iff \sigma \in \mathcal{L}(\mathcal{G})?$ %\footnote{Strictly speaking, $\mathbf{M} = \mathbf{M} + \mathbf{M}^2$ is only necessary if we need to do fixedpoint iteration. Since we solve for $\mathbf{M}^*$ and $S \in \mathcal{T}$ directly, then unlike Valiant, we can solve for the computationally more efficient fixpoint $\mathbf{M} = \mathbf{M}^2$.}

%While theoretically elegant, this decision procedure can be optimized by lowering onto a rank-3 binary tensor.
    Note that $\bigoplus_{k = 1}^n \mathbf{M}_{ik} \otimes \mathbf{M}_{kj}$ has cardinality bounded by $|V|$ and is thus representable as a fixed-length vector using the characteristic function, $\mathds{1}$. In particular, $\oplus, \otimes$ are defined as $\boxplus, \boxtimes$, so that the following diagram commutes:

    \[\begin{tikzcd}[row sep=huge, column sep=huge]
          V \times V \arrow[r, "\oplus/\otimes"] \arrow[d, "\mathds{1}^2"]
          & V \arrow[d, "\mathds{1}\phantom{^{-1}}"] \\
          \mathbb{B}^{|V|} \times \mathbb{B}^{|V|} \arrow[r, "\boxplus/\boxtimes", labels=below] \arrow[u, "\mathds{1}^{-2}"]
          & \mathbb{B}^{|V|} \arrow[u, "\mathds{1}^{-1}"]
    \end{tikzcd}\]

%\noindent The compactness of this representation can be improved via a combinatorial number system without loss of generality, although $\mathds{1}$ is a convenient encoding for SAT.

    \noindent Full details of the bisimilarity between parsing and matrix multiplication can be found in Valiant~\cite{valiant1975general}, who shows its time complexity to be $\mathcal{O}(n^\omega)$ where $\omega$ is the matrix multiplication bound ($\omega < 2.77$), and Lee~\cite{lee2002fast}, who shows that speedups to Boolean matrix multiplication are realizable by CFL parsers. %Assuming sparsity, this technique is typically linearithmic.%, and is believed to be the most efficient procedure for CFL recognition to date.

    \subsection{Sampling k-combinations without replacement}

    \noindent Let $\textbf{M}: \text{GF}(2^{n\times n})$ be a matrix whose structure is depicted in Eq.~\ref{eq:lfsr}, where $P$ is a feedback polynomial over $GF(2^n)$ with coefficients $P_{1\ldots n}$ and semiring operators $\oplus := \veebar, \otimes := \land$. Selecting any $V \neq \mathbf{0}$ and coefficients $P_{1\ldots n}$ from a known \textit{primitive polynomial} then powering the matrix $\mathbf{M}$ generates an ergodic sequence over GF$(2^n)$, as shown in Eq.~\ref{eq:ergo}.

    \begin{align}
        \mathbf{M}^tV = \begin{pNiceMatrix}[nullify-dots,xdots/line-style=loosely dotted]
           P_1    & \cdd  &      &       &      & P_n \\
           \top   & \circ & \cdd &       &      & \circ \\
           \circ  & \ddd  & \ddd &       &      & \vdd \\
           \vdd   & \ddd  &      &       &      & \\
                  &       &      &       &      & \\
           \circ  & \cdd  &      & \circ & \top & \circ
        \end{pNiceMatrix}^t
        \begin{pNiceMatrix}[nullify-dots,xdots/line-style=loosely dotted]
            V_1 \\
            \vdd\\
            \\
            \\
            \\
            V_n
        \end{pNiceMatrix}\label{eq:lfsr}\\
        \mathbf{S} = \begin{pmatrix}V & \mathbf{M}V & \mathbf{M}^{2}V & \mathbf{M}^{3}V & \cdots & \mathbf{M}^{2^n-1}V \end{pmatrix}\label{eq:ergo}
    \end{align}

    \noindent This sequence has \textit{full periodicity}, in other words, for all $i, j \in [0, 2^n), \mathbf{S}_i = \mathbf{S}_j \Rightarrow i = j$. To uniformly sample $\bm\sigma \sim \Sigma^n$ without replacement, we form an injection $GF(2^n)\rightharpoonup\Sigma^d$, cycle through $\mathbf{S}$, then discard samples that do not identify an element in any indexed dimension. This procedure rejects $(1 - |\Sigma|2^{-\lceil\log_2|\Sigma|\rceil})^d$ samples on average and requires $\sim\mathcal{O}(1)$ per sample and $\mathcal{O}(2^n)$ to exhaustively search the space.

    \noindent For example, in order to sample $\mathbf\sigma \sim \Sigma^2 = \{A, B, C\}^2$, we could use the primitive polynomial $x^4 + x^3 +1$ shown below:


    \[\begin{array}{rccccccccc}{
        i & 0  &  1  &  2 &  3  &  4  &  5  &  6  &  7 \\
        \mathbf{S}_i & 1000 & 0100 & 0010 & 1001 & 1100 & 0110 & 1011 & 0101 \\
        \mathbf\sigma & \text{C A}  & \text{B A}  & \text{A C}  & \text{C B}  &  & \text{B C}  &  & \text{B B}\\
    }\]

    \noindent We will use this technique to lazily sample from the space of hole configurations without replacement as described in \S\ref{sec:holes}.

    \subsection{Encoding CFG parsing as SAT solving}\label{sec:sat}

    By allowing the matrix $\mathbf{M}^*$ in Eq.~\ref{eq:fpm} to contain bitvector variables representing holes in the string and nonterminal sets, we obtain a set of multilinear SAT equations whose solutions exactly correspond to the set of admissible repairs and their corresponding parse forests. Specifically, the repairs coincide with holes in the superdiagonal $\mathbf{M}^*_{r+1 = c}$, and the parse forests occur along the upper-triangular entries $\mathbf{M}^*_{r + 1 < c}$.

%We precompute the shadow of fully-resolved substrings before feeding it to the SAT solver. If the substring is known, we can simply compute this directly outside the SAT solver. Shaded regions are bitvector literals and light regions correspond to bitvector variables.

%We illustrate this fact in \S\ref{sec:error}:
%
%\begin{figure}[H]
%    \includegraphics[width=2cm]{../figures/parse1.png}
%    \includegraphics[width=2cm]{../figures/parse2.png}
%    \includegraphics[width=2cm]{../figures/parse3.png}
%    \includegraphics[width=2cm]{../figures/parse4.png}
%\end{figure}

    \newcommand{\ts}[1]{\textsuperscript{#1}}
    \newcommand\non{1\ts{st}}
    \newcommand\ntw{2\ts{nd}}
    \newcommand\nth{3\ts{rd}}
    \newcommand\nfo{4\ts{th}}
    \newcommand\nfi{5\ts{th}}
    \newcommand\nsi{6\ts{th}}
    \newcommand\nse{7\ts{th}}
    \newcommand{\vs}[1]{\{V\}_{\sigma_{#1}}}
    \newcommand\rcr{\rowcolor{black!15}}
    \newcommand\rcw{\rowcolor{white}}
    \newcommand\pcd{\cdot}
    \newcommand\pcp{\phantom\cdot}
    \newcommand\ppp{\phantom{\nse}}
    \newcommand\xno{\text{\emoji{cross-mark}}}

    \begin{figure}[H]
        \[
            \mathbf{M}^* = \begin{pNiceArray}{>{\strut}ccccccc}[margin, extra-margin=2pt,colortbl-like, xdots/line-style=loosely dotted]
                \vno & \rcr \vs{1} &  \mathcal{L}_{1,3} & \mathcal{L}_{1,3} & \rcw \mathcal{V}_{1,4} & \cdd & \mathcal{V}_{1,n} \\
                \vdd & \ddd        &  \rcr\vs{2}        & \mathcal{L}_{2,3} & \rcw\vdd               &      & \vdd \\
                     &             &                    & \rcr\vs{3}        & \rcw                   &      & \\
                     &             &                    &                   & \mathcal{V}_{4,4}      &      & \\
                     &             &                    &                   &                        & \ddd & \\
                     &             &                    &                   &                        &      & \mathcal{V}_{n,n} \\
                \vno & \cdd        &                    &                   &                        &      & \vno
            \end{pNiceArray}
        \]
    \end{figure}

    \noindent Depicted above is a SAT tensor representing \hlgray{$\sigma_1\:\sigma_2\:\sigma_3$}$\:\_\:\ldots\:\_$ where shaded regions demarcate known bitvector literals $\mathcal{L}_{r,c}$ (i.e., representing established nonterminal forests) and unshaded regions correspond to bitvector variables $\mathcal{V}_{r,c}$ (i.e., representing seeded nonterminal forests to be grown). Since $\mathcal{L}_{r,c}$ are fixed, we precompute them outside the SAT solver.

    \subsection{Breadth-bounded tree search}

    The matrix $\mathbf{M}^*$ encodes a superposition of all labeled binary trees of a fixed breadth. Consider the string \texttt{\_ ... \_}, which might generate various parse trees, with labels omitted to emphasize their structure:

    \begin{figure}[H]
        \[
           \mathbf{M}^* = \begin{pNiceArray}{>{\strut}ccccccc}[margin, extra-margin=2pt,colortbl-like, xdots/line-style=loosely dotted]
      \tikzmark{a} & \tikzmark{k}  & \tikzmark{b} & \tikzmark{m} & \tikzmark{c} & \tikzmark{q} & \tikzmark{d} \\
              \vno & \tikzmark{l}  &              & \tikzmark{n} &              & \tikzmark{r} & \tikzmark{w} \\
              \vdd & \ddd          & \tikzmark{e} & \tikzmark{o} & \tikzmark{f} & \tikzmark{s} & \tikzmark{g} \\
                   &               &              & \tikzmark{p} &              & \tikzmark{t} & \tikzmark{x} \\
                   &               &              &              & \tikzmark{h} & \tikzmark{u} & \tikzmark{i} \\
                   &               &              &              &              & \tikzmark{v} &              \\
              \vno & \cdd          &              &              &              & \vno         & \tikzmark{j}
           \end{pNiceArray}
        \begin{tikzpicture}[overlay, remember picture, blubr/.style={-,blue}, redbr/.style={-,red}, grnbr/.style={-,green}]
        \draw [grnbr] ({pic cs:l}) to ({pic cs:r});
        \draw [grnbr] ({pic cs:v}) to ({pic cs:r});
        \draw [grnbr] ({pic cs:r}) to ({pic cs:w});
        \draw [blubr] ({pic cs:a}) to ({pic cs:b});
        \draw [blubr] ({pic cs:e}) to ({pic cs:b});
        \draw [blubr] ({pic cs:h}) to ({pic cs:c});
        \draw [blubr] ({pic cs:b}) to ({pic cs:c});
        \draw [blubr] ({pic cs:c}) to ({pic cs:d});
        \draw [redbr] ({pic cs:h}) to ({pic cs:i});
        \draw [redbr] ({pic cs:j}) to ({pic cs:i});
        \draw [redbr] ({pic cs:e}) to ({pic cs:g});
        \draw [redbr] ({pic cs:i}) to ({pic cs:g});
        \draw [redbr] ({pic cs:g}) to ({pic cs:d});
        \end{tikzpicture}\Rightarrow
        \begin{NiceArray}{>{\strut}ccccccc}[margin, extra-margin=2pt,colortbl-like, xdots/line-style=loosely dotted]
     \tikzmark{a1} & \tikzmark{k1}  & \tikzmark{b1} & \tikzmark{m1} & \tikzmark{c1} & \tikzmark{q1} & \tikzmark{d1} \\
                   & \tikzmark{l1}  &               & \tikzmark{n1} &               & \tikzmark{r1} & \tikzmark{w1} \\
                   &                & \tikzmark{e1} & \tikzmark{o1} & \tikzmark{f1} & \tikzmark{s1} & \tikzmark{g1} \\
                   &                &               & \tikzmark{p1} &               & \tikzmark{t1} & \tikzmark{x1} \\
                   &                &               &               & \tikzmark{h1} & \tikzmark{u1} & \tikzmark{i1} \\
                   &                &               &               &               & \tikzmark{v1} &              \\
                   &                &               &               &               &               & \tikzmark{j1}
           \end{NiceArray}
        \begin{tikzpicture}[overlay, remember picture, redbr/.style={-,red}]
        \draw [redbr] ({pic cs:a1}) to ({pic cs:d1});
        \draw [redbr] ({pic cs:h1}) to ({pic cs:i1});
        \draw [redbr] ({pic cs:j1}) to ({pic cs:i1});
        \draw [redbr] ({pic cs:e1}) to ({pic cs:g1});
        \draw [redbr] ({pic cs:i1}) to ({pic cs:g1});
        \draw [redbr] ({pic cs:g1}) to ({pic cs:d1});
        \end{tikzpicture}
        \begin{NiceArray}{>{\strut}ccccccc}[margin, extra-margin=2pt,colortbl-like, xdots/line-style=loosely dotted]
     \tikzmark{a2} & \tikzmark{k2}  & \tikzmark{b2} & \tikzmark{m2} & \tikzmark{c2} & \tikzmark{q2} & \tikzmark{d2} \\
                   & \tikzmark{l2}  &               & \tikzmark{n2} &               & \tikzmark{r2} & \tikzmark{w2} \\
                   &                & \tikzmark{e2} & \tikzmark{o2} & \tikzmark{f2} & \tikzmark{s2} & \tikzmark{g2} \\
                   &                &               & \tikzmark{p2} &               & \tikzmark{t2} & \tikzmark{x2} \\
                   &                &               &               & \tikzmark{h2} & \tikzmark{u2} & \tikzmark{i2} \\
                   &                &               &               &               & \tikzmark{v2} &              \\
                   &                &               &               &               &               & \tikzmark{j2}
           \end{NiceArray}
        \begin{tikzpicture}[overlay, remember picture, blubr/.style={-,blue}]
        \draw [blubr] ({pic cs:a2}) to ({pic cs:b2});
        \draw [blubr] ({pic cs:e2}) to ({pic cs:b2});
        \draw [blubr] ({pic cs:h2}) to ({pic cs:c2});
        \draw [blubr] ({pic cs:b2}) to ({pic cs:c2});
        \draw [blubr] ({pic cs:c2}) to ({pic cs:d2});
        \draw [blubr] ({pic cs:j2}) to ({pic cs:d2});
        \end{tikzpicture}
        \begin{NiceArray}{>{\strut}ccccccc}[margin, extra-margin=2pt,colortbl-like, xdots/line-style=loosely dotted]
     \tikzmark{a3} & \tikzmark{k3}  & \tikzmark{b3} & \tikzmark{m3} & \tikzmark{c3} & \tikzmark{q3} & \tikzmark{d3} \\
                   & \tikzmark{l3}  &               & \tikzmark{n3} &               & \tikzmark{r3} & \tikzmark{w3} \\
                   &                & \tikzmark{e3} & \tikzmark{o3} & \tikzmark{f3} & \tikzmark{s3} & \tikzmark{g3} \\
                   &                &               & \tikzmark{p3} &               & \tikzmark{t3} & \tikzmark{x3} \\
                   &                &               &               & \tikzmark{h3} & \tikzmark{u3} & \tikzmark{i3} \\
                   &                &               &               &               & \tikzmark{v3} &              \\
                   &                &               &               &               &               & \tikzmark{j3}
           \end{NiceArray}
        \begin{tikzpicture}[overlay, remember picture, grnbr/.style={-,green}]
            \draw [grnbr] ({pic cs:l3}) to ({pic cs:r3});
            \draw [grnbr] ({pic cs:n3}) to ({pic cs:p3});
            \draw [grnbr] ({pic cs:v3}) to ({pic cs:r3});
            \draw [grnbr] ({pic cs:r3}) to ({pic cs:w3});
            \draw [grnbr] ({pic cs:j3}) to ({pic cs:d3});
            \draw [grnbr] ({pic cs:a3}) to ({pic cs:d3});
        \end{tikzpicture}\ldots
    \]
    \end{figure}

    \subsection{Deletion, substitution, and insertion}\label{sec:dsi}

    Deletion, substitution and insertion can be simulated by first adding a left- and right- $\varepsilon$-production to each unit production:

    \begin{center}
        \AxiomC{$\Gamma \vdash \varepsilon \in \Sigma$}
        \RightLabel{$\varepsilon\textsc{-dup}$}
        \UnaryInfC{$\Gamma \vdash (\varepsilon^+ \rightarrow \varepsilon \mid \varepsilon^+\:\varepsilon^+) \in P$}
        \DisplayProof
        \hskip 1.5em
        \AxiomC{$\Gamma \vdash (A \rightarrow B) \in P$}
        \RightLabel{$\varepsilon^+\textsc{-int}$}
        \UnaryInfC{$\Gamma \vdash (A \rightarrow B\:\varepsilon^+ \mid \varepsilon^+\:B \mid B) \in P$}
        \DisplayProof
    \end{center}

    \noindent To generate the sketch templates, we substitute two holes at an index-to-be-repaired, $H(\sigma, i) = \sigma_{1\ldots i-1}\:\texttt{\_ \_}\:\sigma_{i+1\ldots n}$, then invoke the SAT solver. Five outcomes are then possible:

    \begin{align}
        &\sigma_{1}\ldots\sigma_{i-1}\:\text{\hlred{$\gamma_1$}\hlred{$\gamma_2$}}\:\sigma_{i+1}\ldots\sigma_{n}, \gamma_{1, 2} = \varepsilon\label{eq:del}\\
        &\sigma_{1}\ldots \sigma_{i-1}\:\text{\hlorange{$\gamma_1$}\hlred{$\gamma_2$}}\:\sigma_{i+1}\ldots \sigma_{n}, \gamma_1 \neq \sigma_i, \gamma_2 = \varepsilon\label{eq:sub1}\\
        &\sigma_{1}\ldots \sigma_{i-1}\:\text{\hlred{$\gamma_1$}\hlorange{$\gamma_2$}}\:\sigma_{i+1}\ldots \sigma_{n}, \gamma_1 = \varepsilon, \gamma_2 \neq \sigma_i\label{eq:sub2}\\
        &\sigma_{1}\ldots\sigma_{i-1}\: \text{\hlorange{$\gamma_1$}\hlgreen{$\gamma_2$}}\:\sigma_{i+1}\ldots\sigma_{n}, \gamma_1 = \sigma_i, \gamma_2 \neq \varepsilon\label{eq:ins1}\\
        &\sigma_{1}\ldots\sigma_{i-1}\: \text{\hlgreen{$\gamma_1$}\hlorange{$\gamma_2$}}\:\sigma_{i+1}\ldots\sigma_{n}, \gamma_1 \notin \{\varepsilon, \sigma_i\}, \gamma_2 = \sigma_i\label{eq:ins2}
    \end{align}

    \noindent Eq.~(\ref{eq:del}) corresponds to deletion, Eqs.~(\ref{eq:sub1},~\ref{eq:sub2}) correspond to substitution, and Eqs.~(\ref{eq:ins1},~\ref{eq:ins2}) correspond to insertion. This procedure is repeated for all indices in the replacement set. The solutions returned by the SAT solver will be strictly equivalent to handling each edit operation as separate cases.

    \section{Error Recovery}\label{sec:error}

    Unlike classical parsers which need special care to recover from errors, if the input string does not parse, Tidyparse can return partial subtrees. If no solution exists, the upper triangular entries will appear as a jagged-shaped ridge whose peaks represent the roots of parsable ASTs. These provide a natural debugging environment to aid the repair process.

    \begin{tidyinput}
        true and true ! and false or true ! true and false(*@\caret{ }@*)
    \end{tidyinput}

    \begin{verbatim}
 Parseable subtrees (3 leaves / 2 branches):
    \end{verbatim}
    \noindent\hspace{0.64cm}\emoji{herb}\hspace{1.70cm}\emoji{herb}\hspace{1.98cm}\emoji{herb}\vspace{-5pt}
    \begin{verbatim}
    └── ! [3]   └── and [4]   └── or [6]
    \end{verbatim}
    \hspace{0.63cm}\emoji{herb}\hspace{3.4cm}\emoji{herb}\vspace{-5pt}
    \begin{verbatim}
    └── S [0..2]          └── S [8..11]
        ├── true [0]          ├── S [8..9]
        ├── and [1]           │   ├── ! [8]
        └── true [2]          │   └── true [9]
                              ├── and [10]
                              └── false [11]
    \end{verbatim}

    \noindent These branches correspond to peaks on the upper triangular (UT) matrix ridge. As depicted in Fig.~\ref{fig:peaks}, we traverse the peaks by decreasing elevation to collect partial AST branches.

    \begin{figure}[H]
        \[
            \begin{NiceMatrix}
                  & \nse & \nsi & \nfi & \nfo & \nth & \ntw & \non & \ppp & \ppp \\
                  &      & \ddd & \ddd & \ddd & \ddd & \ddd & \ddd & \ddd & \ppp \\
 \{V\}_{\sigma_1} & \cdd &      & A    &      &      &      &      &      & \ppp \\
             \vno & \ddd &  T_A & \vdd &      &      &      &      &      & \ppp \\
             \vdd & \ddd &      & \pcd & \cdd &      & B    &      &      & \ppp \\
                  &      &      &      &      & T_B  & \vdd &      &      & \ppp \\
                  &      &      &      &      &      & \pcd & \cdd &      & C    \\
                  &      &      &      &      &      &      &      & T_C  & \vdd \\
                  &      &      &      &      &      &      & \xno &      & \\
                  &      &      &      &      &      &      &      &      & \\
                  &      &      &      &      &      &      &      &      & \\
                  &      &      &      &      &      &      &      & \ppp & \{V\}_{\sigma_n} \\
             \vno & \cdd &      &      &      &      &      &      & \vno &
            \end{NiceMatrix}
        \]\caption{Peaks along the UT matrix ridge correspond to maximally parseable substrings. By recursing over upper diagonals of decreasing elevation and discarding all subtrees that fall under the shadow of another's canopy, we can recover the partial subtrees. The example depicted above contains three such branches, rooted at nonterminals $C, B, A$.}\label{fig:peaks}
    \end{figure}

    \section{Tree Denormalization}

% https://www.ling.upenn.edu/advice/latex/qtree/qtreenotes.pdf
% https://cpb-us-w2.wpmucdn.com/campuspress.yale.edu/dist/0/119/files/2014/12/sec-10.17-drawing-arrows-2ek9r2b.pdf

    Our parser emits a binary forest consisting of parse trees for the candidate string according to the CNF grammar, however this forest contains many so-called \textit{Krummholz}, or \textit{flag trees}, often found clinging to windy ridges and mountainsides.

    \begin{figure}[H]
        \resizebox{.50\textwidth}{!}{
            \begin{tabular}{ll}
                \Tree [.\texttt{S} \tikz\node(v1){\texttt{true}} [.$\ccancel{\texttt{and.S}}$ \tikz\node(v3){\texttt{and}} [.\texttt{S} \tikz\node(v5){\texttt{(}} [.$\ccancel{\texttt{S.)}}$ [.\texttt{S} \tikz\node(v9){\texttt{false}} [.$\ccancel{\texttt{or.S}}$ \tikz\node(v11){\texttt{or}} [.\texttt{S} \texttt{!} \texttt{true} ] ] ] \tikz\node(v7){\texttt{)}} ] ] ] ]
%    \Tree [.S [.NP John ] [.VP [.\tikz\node(v1){V}; sleeps ] ] ]
                \hspace{-2cm}
                &
                \Tree [.\texttt{S} \tikz\node(v2){\texttt{true}} \tikz\node(v4){\texttt{and}} [.\texttt{S} \tikz\node(v6){\texttt{(}} [.\texttt{S} \tikz\node(v10){\texttt{false}} \tikz\node(v12){\texttt{or}} [.\texttt{S} \texttt{!} \texttt{true} ] ] \tikz\node(v8){\texttt{)}} ] ]\\\\
%    \Tree [.\tikz\node(v2){V}; [.\tikz\node(v3){V}; ] [.Adv {a lot} ] ]
                \hspace{1cm}\huge{Pre-Denormalization} & \hspace{3cm}\huge{Post-Denormalization}
            \end{tabular}
            \begin{tikzpicture}[overlay]
%    \draw [red,dashed,-stealth] (v1) to[bend left] (v2);
                \draw [red,dashed,-stealth] (v3) to[bend left] (v4);
%    \draw [red,dashed,-stealth] (v5) to[bend left] (v6);
                \draw [red,dashed,-stealth] (v7) to[bend left] (v8);
%    \draw [red,dashed,-stealth] (v9) to[bend right] (v10);
                \draw [red,dashed,-stealth] (v11) to[bend right] (v12);
            \end{tikzpicture}
        }
%    \caption{Result of applying Algorithm~\ref{alg:cap} to the tree obtained by parsing the string: \texttt{true and ( false or ! true )}.}
    \end{figure}
    \begin{algorithm}
        \caption{Rewrite procedure for tree denormalization}\label{alg:cap}
        \begin{algorithmic}
            \Procedure{Denormalize}{\texttt{t: Tree}}
                \State $\texttt{stems} \leftarrow \{\:\textsc{Denormalize}(\texttt{c}) \mid \texttt{c} \in \texttt{t.children}\:\}$
                \If{$\texttt{t.root} \in V_{\mathcal{G}'} \setminus V_{\mathcal{G}}$}
                    \State \textbf{return } \texttt{stems} \Comment{Drop synthetic nonterminals.}
                \Else\Comment{Graft the denormalized children on root.}
                \State \textbf{return } $\{\:\texttt{Tree(root, stems)}\:\}$
                \EndIf
            \EndProcedure
        \end{algorithmic}
    \end{algorithm}

    \noindent To recover a parse tree congruent with the user-specified grammar, we prune all synthetic nodes and graft their stems onto the grandparent via a simple recursive procedure (Alg.~\ref{alg:cap}).%, which is used to denormalize both complete and partial ASTs (cf. \S~\ref{sec:error}) alike.

    \subfile{brzozowski}

\section{Closure and simplification of subexpressions}

    Clearly, the solving process is polynomial in the size of the string. For the sake of complexity, it would be convenient if well-formed subexpressions could be collapsed into a single nonterminal, or multiple nonterminals (in case of ambiguity). Naturally, this raises the question of when can partial derivations be simplified? This transformation is admissible and indeed desirable when the subexpression is ``complete'', i.e., its derivation cannot be altered by appending or prepending text. Returning to Fig. 4, under what circumstances is the following reduction admissible?

\begin{figure}[H]
 \[
    \mathbf{M}^* = \begin{pNiceArray}{>{\strut}ccccccc}[margin, extra-margin=2pt,colortbl-like, xdots/line-style=loosely dotted]
       \vno & \rcr \vs{1} &  \mathcal{L}_{1,3} & \mathcal{L}_{1,3} & \rcw \mathcal{V}_{1,4} & \cdd & \mathcal{V}_{1,n} \\
       \vdd & \ddd        &  \rcr\vs{2}        & \mathcal{L}_{2,3} & \rcw\vdd               &      & \vdd \\
            &             &                    & \rcr\vs{3}        & \rcw                   &      & \\
            &             &                    &                   & \mathcal{V}_{4,4}      &      & \\
            &             &                    &                   &                        & \ddd & \\
            &             &                    &                   &                        &      & \mathcal{V}_{n,n} \\
       \vno & \cdd        &                    &                   &                        &      & \vno
    \end{pNiceArray} \equiv
    \begin{pNiceArray}{>{\strut}ccccccc}[margin, extra-margin=2pt,colortbl-like, xdots/line-style=loosely dotted]
       \vno & \rcr\mathcal{L}_{1,3} & \rcw\mathcal{V}_{1,4} & \cdd & \mathcal{V}_{1,n} \\
       \vdd & \ddd                  & \mathcal{V}_{2,4}     &      & \vdd \\
            &                       &                       & \ddd & \\
            &                       &                       &      & \mathcal{V}_{n,n} \\
       \vno & \cdd                  &                       &      & \vno
    \end{pNiceArray}
 \]
\end{figure}

    For example, the string \texttt{( - b )} is morally \textit{complete} in the sense that inserting adjacent text should not alter the interior derivation, while \texttt{- b} is not, as introducing adjacent text (e.g. \texttt{a - b}) may alter the derivation of its contents depending on the structure of the CFG. How can we formalize this argument to work on arbitrary (e.g., potentially ambiguous) grammars? This question can be reduced to a quotient: Does there exist another nonterminal, when joined with the substring in question, that will ``strip away'' any of its tokens, leading to another derivation?

    \section{Realtime Error Correction}\label{sec:holes}

    Now that we have a reliable method to fix \textit{localized} errors, $S: \mathcal{G} \times (\Sigma\cup\{\varepsilon, \texttt{\_}\})^n \rightarrow \{\Sigma^n\}\subseteq \mathcal{L}_\mathcal{G}$, given an input string, $\Sigma^n$, where should we put the holes? Assuming $k$ holes, there are ${n \choose k}$ possible hole configurations (HCs), each with $(|\Sigma| + 1)^{2k}$ possible repairs (before parsing, cf. Eqs.~\ref{eq:del}-\ref{eq:ins2}). In practice, depending on $n$ and $k$, this space can be intractable to search through exhaustively, so to facilitate real-time assistance we prioritize likely repairs according to an eight-step procedure:

    \begin{enumerate}
        \item Fetch the most recent CFG and string from the editor.
        \item Exclude parsable substrings from hollowing.
        \item Lazily enumerate all HCs of increasing length.
        \item Sample HCs without replacement using Eq.~\ref{eq:ergo}.
        \item Prioritize HCs first by distance to caret index, then by Earthmover's distance to a set of suspicious indices.$^*$
        \item Translate HCs to sketch templates using~\S\ref{sec:dsi}.
        \item Feed sketch templates to an incremental SAT solver.
        \item Decode and rerank models by Levenshtein distance.
    \end{enumerate}

    \noindent $^*$ These locations can be supplied by local edit history or using tokenwise perplexity from a neural language model. Once a new repair is discovered, it is immediately displayed. Incoming keystrokes interrupt and reset the solving process.

    \section{Practical Example}

    Tidyparse requires a grammar -- this can be either provided by the user or ingested from a BNF-like specification. The following is a slightly more complex grammar, designed to resemble a more realistic use case:

\begin{tidyinput}
S -> A | V | ( X , X ) | X X | ( X )
A -> Fun | F | L | L in X
Fun -> fun V (*@`@*)->(*@`@*) X
F -> if X then X else X
L -> let V = X | let rec V = X
V -> Vexp | ( Vexp ) | Vexp Vexp
Vexp -> VarName | FunName | Vexp VO Vexp
Vexp -> ( VarName , VarName ) | Vexp Vexp
VarName -> a | b | c | d | e | ... | z
FunName -> foldright | map | filter
VO ->  + | - | * | / | > | = | < | (*@`@*)||(*@`@*) | &&
---
let curry f = ( fun x y -> f ( _ _ _(*@\caret{ }@*)) )
\end{tidyinput}
\begin{tidyoutput}
let curry f = ( fun x y -> f ( (*@\hlorange{<X>}@*) ) )
let curry f = ( fun x y -> f ( (*@\hlorange{<FunName>}@*) ) )
let curry f = ( fun x y -> f ( (*@\hlorange{curry}@*) (*@\hlorange{<X>}@*) ) )
...
\end{tidyoutput}

    \subsection{Grammar Assistance}

    Tidyparse uses a CFG to parse the CFG, so it can provide assistance while the user is designing the CFG. For example, if the CFG does not parse, it will suggest possible fixes. In the future, we intend to use this functionality to perform example-based codesign and grammar induction.

\begin{tidyinput}
B -> true | false | (*@\caret{ }@*)
\end{tidyinput}
\begin{tidyoutput}
B -> true | false (*@\hlred{ }@*)
B -> true | false (*@\hlorange{<RHS>}@*)
B -> true | false | (*@\hlgreen{<RHS>}@*)
...
\end{tidyoutput}

    \subsection{Interactive Nonterminal Expansion}

    Users can interactively build up a complex expression by placing the caret over a placeholder they wish to expand,

\begin{tidyinput}
if <(*@\caret{V}@*)exp> X then <Vexp> else <Vexp>
\end{tidyinput}

    \noindent then invoking Tidyparse by pressing \keys{\ctrl + \SPACE}, to receive a list of expressions consistient with the grammar:

\begin{tidyoutput}
if (*@\hlorange{map}@*) X then <Vexp> else <Vexp>
if (*@\hlorange{uncurry}@*) X then <Vexp> else <Vexp>
if (*@\hlorange{foldright}@*) X then <Vexp> else <Vexp>
...
\end{tidyoutput}

%There are some more examples too.
%
%The line between parsing and computation is blurry.

\section{Neural language modeling}
\begin{figure}[H]
\begin{center}
\begin{tabular}{|p{5cm}|p{5cm}|}
\hline\\[-1em]1.a) Original method  &  1.b) Synonymous variant\\[-1em]\\\hline
\begin{lstlisting}[basicstyle=\ttfamily\lst@ifdisplaystyle\footnotesize\fi, language=kotlin]
public void flush(int b) {
    buffer.write((byte) b);
    buffer.compact();
}
\end{lstlisting} & \begin{lstlisting}[basicstyle=\ttfamily\lst@ifdisplaystyle\footnotesize\fi, language=kotlin]
public void flush(int b) {
    (*@\hlred{cushion}@*).write((byte) b);
    (*@\hlred{cushion}@*).compact();
}
\end{lstlisting}
\\\hline\\[-1em]2.a) Multi-masked method   &  2.b) Multi-masked variant\\[-1em]\\\hline
\begin{lstlisting}[basicstyle=\ttfamily\lst@ifdisplaystyle\footnotesize\fi, language=kotlin]
public void <MASK>(int b) {
    buffer.<MASK>((byte) b);
    <MASK>.compact();
}
\end{lstlisting} & \begin{lstlisting}[basicstyle=\ttfamily\lst@ifdisplaystyle\footnotesize\fi, language=kotlin]
public void <MASK>(int b) {
    cushion.<MASK>((byte) b);
    <MASK>.compact();
}
\end{lstlisting}
\\\hline\\[-1em]3.a) Model predictions  &  3.b) Model predictions\\[-1em]\\\hline
\begin{lstlisting}[basicstyle=\ttfamily\lst@ifdisplaystyle\footnotesize\fi, language=kotlin]
public void (*@\hl{output}@*)(int b) {
    buffer.write((byte) b);
    buffer.compact();
}
\end{lstlisting} & \begin{lstlisting}[basicstyle=\ttfamily\lst@ifdisplaystyle\footnotesize\fi, language=kotlin]
public void (*@\hl{append}@*)(int b) {
    cushion.(*@\hl{add}@*)((byte) b);
    cushion.compact();
}
\end{lstlisting} \\\hline
\end{tabular}
\end{center}
\end{figure}

    \pagebreak
    \section{Evaluation}

    In the following benchmarks, we measure the wall clock time required to synthesize solutions to length-50 strings sampled from various Dyck languages, where Dyck-n is the Dyck language containing n types of balanced parentheses.

\begin{tidyinput}
D1 -> () | ( D1 ) | D1 D1
D2 -> D1 | [ ] | ( D2 ) | [ D2 ] | D2 D2
D3 -> D2 | { } | ( D3 ) | [ D3 ] | { D3 } | D3 D3
\end{tidyinput}

    \noindent In the first experiment, we sample a random valid string $\sigma \sim \Sigma^{50} \cap \mathcal{L}_{\text{Dyck-n}}$, then replace a fixed number tokens with holes and measure the average time taken to decode ten syntactically-admissible repairs across 100 trial runs.

    \begin{tikzpicture}
        \begin{axis}[
            width=8.3cm,
            title={\hspace{-1cm}\textbf{Error correction time with known locations}},
            ybar,
            bar width=4pt,
            xlabel={Number of holes},
            ylabel={ms to synthesize 10 repairs},
            xtick=data,
            axis x line*=bottom,
            axis y line*=left,
            ytick pos=left,
            xticklabels from table={\loctimings}{holes},
            ymajorgrids,
            legend pos=north west,
            error bars/y dir=both,
            error bars/y explicit
        ]
            \addplot table [x expr=\coordindex, y=d1, y error=d1err]{\loctimings};
            \addplot table [x expr=\coordindex, y=d2, y error=d2err]{\loctimings};
            \addplot table [x expr=\coordindex, y=d3, y error=d3err]{\loctimings};
            \addplot table [x expr=\coordindex, y=d4, y error=d4err]{\loctimings};
            \legend{Dyck-1, Dyck-2, Dyck-3, Dyck-4}
        \end{axis}
    \end{tikzpicture}

    \noindent In the second experiment, we sample a random valid string as before, but delete p tokens at random and rather than provide the location(s), ask our model to solve for both the location(s) and repair by sampling uniformly from all n-token HCs, then measure the total time required to decode the first admissible repair. Note the the logarithmic scale on the y-axis.

    \begin{tikzpicture}
        \begin{axis}[
            width=8.3cm,
            height=6.6cm,
            title={\hspace{-1cm}\textbf{Error correction time with unknown locations}},
            ybar,
            bar width=20pt,
            xlabel={Number of errors},
            ylabel={ms to synthesize 1 repair},
            xtick=data,
            axis x line*=bottom,
            axis y line*=left,
            enlarge x limits={abs=0.5},
            ymode=log,
            ytick pos=left,
            xticklabels from table={\unloctimings}{errors},
            ymajorgrids,
            legend pos=north west,
            error bars/y dir=both,
            error bars/y explicit
        ]
            \addplot table [x expr=\coordindex, y=d1]{\unloctimings};
            \addplot table [x expr=\coordindex, y=d2]{\unloctimings};
            \addplot table [x expr=\coordindex, y=d3]{\unloctimings};
            \legend{Dyck-1, Dyck-2, Dyck-3}
        \end{axis}
    \end{tikzpicture}

    \subsection{Task Difficulty}

    \noindent\textbf{Level \textonehalf} - Incomplete code (all missing tokens at end)

    \noindent\textbf{Level 1} - Known number of errors at known locations

    \noindent\textbf{Level 2} - Known number of errors at unknown locations

    \noindent\textbf{Level 3} - Unknown number of errors at unknown locations

    \subsection{Repair Datasets}
    Synthetic - Synthetic errors in natural code snippets
    Natural - Natural errors and fixes mined from Git history
    \subsection{Evaluation Metrics}
    Syntactic validity - Only considers whether the repair parses
    Repair alignment - Measures string distance to true fix
    \subsection{Model configurations}
    Model configurations - LLM, ECP, ECP + LLM
    GraphCodeBERT
    RobertA
    Incoder
    CarperAI?

    \section{Discussion}

    While error correction with a few errors is tolerable, latency can vary depending on many factors including string length and grammar size. If errors are known to be concentrated in specific locations, such as the beginning or end of a string, then latency is typically below 500ms. Should errors occur uniformly at random, admissible repairs can take longer to discover, however these scenarios are unusual in our experience. We observe that errors are typically concentrated nearby historical edit locations, which can be retrieved from the IDE or version control. Further optimizations that reduce the total number of repairs checked are possible by eliminating improbable sketch templates.

    Tidyparse in its current form has a number of technical shortcomings: firstly it does not incorporate any neural language modeling technology at present, an omission we hope to address in the near future. Training a language model to predict likely repair locations and rank admissible results could lead to lower overall latency and more natural repairs.

    Secondly, our current method generates sketch templates using a na\"ive enumerative search, feeding them individually to the SAT solver, which has the tendency to duplicate prior work and introduces unnecessary thrashing. Considering recent extensions of Boolean matrix-based parsing to linear context-free rewriting systems (LCFRS)~\cite{cohen2016parsing}, it may be feasible to search through these edits within the SAT solver, leading to yet unrealized and possibly significant speedups.

    Lastly and perhaps most significantly, Tidyparse does not incorporate any semantic constraints, so its repairs while syntactically admissible, are not guaranteed to be semantically valid. We note however, that it is possible to encode type-based semantic constraints into the solver and intend to explore this direction more fully in future work.

    Although not intended to be a dedicated parser and we make no attempt to rigorously compare parsing latency, parsing valid strings with Tidyparse is typically competitive with classical parsing methods. Our primary motivation is to facilitate the usability and explainability of parsing with errors. We envision three primary use cases: (1) helping novice programmers become more quickly familiar with a new programming language (2) autocorrecting common typos among proficient but forgetful programmers and (3) as a prototyping tool for PL educators and designers.

    Featuring a grammar editor and built-in SAT solver, Tidyparse helps developers navigate the language design space, visualize syntax trees, debug parsing errors and quickly generate simple examples and counterexamples for testing. Although the algorithm may seem esoteric at first glance, in our experience it is much more interpretable than classical parsers, which exhibit poor error-recovery and diagnostics.

    \section{Conclusion}

    Tidyparse accepts a CFG and a string to parse. If the string is valid, it returns the parse forest, otherwise, it returns a set of repairs, ordered by their Levenshtein edit distance to the invalid string. Our method compiles each CFG and candidate string onto a matrix dynamical system using an extended version of Valiant's construction and solves for its fixedpoints using an incremental SAT solver. This approach to parsing has many advantages, enabling us to repair syntax errors, correct typos and generate parse trees for incomplete strings. By allowing the string to contain holes, repairs can contain either concrete tokens or nonterminals, which can be manually expanded by the user or a neural-guided search procedure. From a theoretical standpoint, this technique is particularly amenable to neural program synthesis and repair, naturally integrating with the masked-language-modeling task (MLM) used by transformer-based neural language models.

    From a practical standpoint, we have implemented our approach as an IDE plugin and demonstrated its viability as a tool for live programming. Tidyparse is capable of generating repairs for invalid code in a range of toy languages. We plan to continue expanding its grammar and autocorrection functionality to cover a broader range of languages and hope to conduct a more thorough user study to validate its effectiveness in the near future. Further examples can be found at our GitHub repository: \url{https://github.com/breandan/tidyparse}
%\begin{itemize}
%\item Error correction.
%\item Program repair.
%\item Program synthesis.
%\item Parsing with holes.
%\item Naturally integrates with masked language model (MLM)-based neural program repair.
%\item Parsing with natural error recovery.
%\item Helps to facilitate language learning.
%\item GPU acceleration.
%\end{itemize}

    \section{Acknowledgements}
    The first author would like to thank his co-advisor Xujie Si for providing many helpful suggestions during the development of this project, including the optimized fixpoint, test cases, and tree denomalization procedure, Zhixin Xiong for contributing the OCaml grammar and collaborator Nghi Bui at FPT Software for early feedback on the IDE plugin.
    \bibliography{../bib/acmart}
\end{document}